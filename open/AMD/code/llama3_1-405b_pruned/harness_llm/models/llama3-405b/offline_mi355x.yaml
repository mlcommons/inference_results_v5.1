# benchmark details
benchmark_name: llama3_1-405b
scenario: offline
test_mode: performance
backend: vllm

vllm_env_config:
  VLLM_LOGGING_LEVEL: "ERROR"
  NCCL_MIN_NCHANNELS: 112
  RAY_EXPERIMENTAL_NOSET_ROCR_VISIBLE_DEVICES: 1
  TOKENIZERS_PARALLELISM: False
  VLLM_INSTALL_PUNICA_KERNELS: 1
  #VLLM_USE_ROCM_CUSTOM_PAGED_ATTN: 1
  VLLM_USE_TRITON_FLASH_ATTN: 1
  VLLM_USE_AITER_TRITON_ROPE: 1
  VLLM_USE_AITER_TRITON_SILU_MUL: 1
  TRITON_HIP_ASYNC_COPY_BYPASS_PERMUTE: 1
  AMDGCN_USE_BUFFER_OPS: 1
  TRITON_HIP_USE_ASYNC_COPY: 1
  TRITON_HIP_USE_BLOCK_PINGPONG: 1
  # **** the following are not considered for this docker image
  VLLM_ROCM_USE_AITER_PAGED_ATTN: 1
  VLLM_TRITON_FP4_GEMM_USE_ASM: 1
  TRITON_HIP_ASYNC_FAST_SWIZZLE: 1
  TRITON_HIP_PRESHUFFLE_SCALES: 1
  VLLM_ROCM_USE_AITER: 1
  VLLM_ROCM_USE_AITER_RMSNORM: 1
  VLLM_SCHED_PREFILL_KVC_FREEPCT: 0.75
  VLLM_USE_WEIGHT_STREAMING: true
  NCCL_NSOCKS_PERTHREAD: 4
  NCCL_SOCKET_NTHREADS: 4
  RCCL_MSCCL_ENABLE: 1
  HARNESS_GC_LIMIT: 100000

# configuration related to the LLM model.
vllm_engine_config:
  model: /model/llama3.1-405b/fp4_quantized/pruned_59_84
  dtype: BFloat16
  tensor_parallel_size: 1
  num_scheduler_steps: 16
  quantization: quark
  max_model_len: 22000 
  gpu_memory_utilization: 0.97
  max_seq_len_to_capture: 22000 
  enforce_eager: False 
  disable_custom_all_reduce: False
  max_num_batched_tokens: 22000 
  max_num_seqs: 2816
  enable_chunked_prefill: False
  enable_prefix_caching: False
  disable_log_stats: False

# configuration related to the sampling params
vllm_sampling_config:
  temperature: 1
  seed: 42
  top_p: 1
  top_k: 1
  max_tokens: 2000
  min_tokens: 2
  ignore_eos: False
  detokenize: False

# configuration related to the harness tests.
harness_config:
  dataset_path: /data/llama3.1-405b/mlperf_llama3.1_405b_dataset_8313_processed_fp16_eval.pkl
  mlperf_conf_path: /app/mlperf_inference/mlperf.conf
  user_conf_path: /lab-mlperf-inference/code/user_mi355x.conf
  target_qps: -1 # 80
  total_sample_count: 33252
  output_log_dir: /app/logs
  load_balance_token_weight: 0.005
  enable_log_trace: False
  warmup_duration: 0
  enable_warmup: True
  warm_up_sample_count_per_server: 20
  sorting:
    strategy: modulo_desc
  device_count: 8
  duration_sec: -1
