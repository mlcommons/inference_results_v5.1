
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>quark.onnx.tools.save_tensor_hist &#8212; Quark 0.8.0rc2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/custom.css?v=6b4ca4e1" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/rocm_header.css?v=4044f309" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/rocm_footer.css?v=25204c5a" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/fonts.css?v=fcff5274" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../../_static/documentation_options.js?v=d42b94c0"></script>
    <script src="../../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="../../../../_static/code_word_breaks.js?v=327952c4"></script>
    <script async="async" src="../../../../_static/renameVersionLinks.js?v=929fe5e4"></script>
    <script async="async" src="../../../../_static/rdcMisc.js?v=01f88d96"></script>
    <script async="async" src="../../../../_static/theme_mode_captions.js?v=15f4ec5d"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/quark/onnx/tools/save_tensor_hist';</script>
    <script async="async" src="https://download.amd.com/js/analytics/analyticsinit.js"></script>
    <link rel="icon" href="https://www.amd.com/themes/custom/amd/favicon.ico"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
<script type="text/javascript">
    window.addEventListener("load", function(event) {
        var coll = document.querySelectorAll('.toggle > .header');  // sdelect the toggles header.
        var i;

        for (i = 0; i < coll.length; i++) {                        
            coll[i].innerText = "Show code ▼\n\n";
            
            coll[i].addEventListener("click", function() {
                var content = this.nextElementSibling;  // code block.
                if (content.style.display === "block") {
                    content.style.display = "none";
                    this.innerText = "Show code ▼\n\n";
                } else {
                    content.style.display = "block";
                    this.innerText = "Hide code ▶";
                }
            });
        }
    });
</script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  

<header class="common-header" >
    <nav class="navbar navbar-expand-xl">
        <div class="container-fluid main-nav rocm-header">
            
            <button class="navbar-toggler collapsed" id="nav-icon" data-tracking-information="mainMenuToggle" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="header-logo">
                <a class="navbar-brand" href="https://www.amd.com/">
                    <img src="../../../../_static/images/amd-header-logo.svg" alt="AMD Logo" title="AMD Logo" width="90" class="d-inline-block align-text-top hover-opacity"/>
                </a>
                <div class="vr vr mx-40 my-25"></div>
                <a class="klavika-font hover-opacity" href="https://quark.docs.amd.com">Quark</a>
                <a class="header-all-versions" href="https://quark.docs.amd.com/latest/versions.html">Version List</a>
            </div>
            <div class="icon-nav text-center d-flex ms-auto">
            </div>
        </div>
    </nav>
    
    <nav class="navbar navbar-expand-xl second-level-nav">
        <div class="container-fluid main-nav">
            <div class="navbar-nav-container collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-mega me-auto mb-2 mb-lg-0 col-xl-10">
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark" id="navgithub" role="button" aria-expanded="false" target="_blank" >
                                GitHub
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark/issues/new/choose" id="navsupport" role="button" aria-expanded="false" target="_blank" >
                                Support
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
    </nav>
    
</header>


  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Quark 0.8.0rc2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../release_note.html">Release Information</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started with AMD Quark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../intro.html">Introduction to Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../install.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../basic_usage.html">Basic Usage</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/basic_usage_pytorch.html">AMD Quark for PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/basic_usage_onnx.html">AMD Quark for ONNX</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/pytorch_examples.html">Accessing PyTorch Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_diffusers.html">Diffusion Model Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_brevitas.html">AMD Quark Extension for Brevitas Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_pruning.html">Language Model Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_ptq.html">Language Model PTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_qat.html">Language Model QAT</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval.html">Language Model Evaluation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_vision.html">Vision Model Quantization using FX Graph Mode</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../onnx/onnx_examples.html">Accessing ONNX Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_BFP.html">Block Floating Point (BFP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_MX.html">MX Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_adaround.html">Fast Finetune AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_adaquant.html">Fast Finetune AdaQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_cle.html">Cross-Layer Equalization (CLE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_gptq.html">GPTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_smoothquant.html">Smooth Quant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_quarot.html">QuaRot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_dynamic_quantization_llama2.html">Quantizing an Llama-2-7b Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_dynamic_quantization_opt.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_image_classification.html">Quantizing a ResNet50-v1-12 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_language_models.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_weights_only_quant_int4_matmul_nbits_llama2.html">Quantizing an Llama-2-7b Model Using the ONNX MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_weights_only_quant_int8_qdq_llama2.html">Quantizating Llama-2-7b model using MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/image_classification_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Image Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/object_detection_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Object Detection Model</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced AMD Quark Features for PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/user_guide_config_description.html">Configuring PyTorch Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/calibration_methods.html">Calibration Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/calibration_datasets.html">Calibration Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/quark_save_load.html">Save and Load Quantized Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/export/quark_export.html">Exporting Quantized Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/export/quark_export_onnx.html">ONNX Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/export/quark_export_hf.html">HuggingFace Format</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../pytorch/export/quark_export_gguf.html">GGUF Format</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/export/gguf_llamacpp.html">Bridge from Quark to llama.cpp</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/export/quark_export_quark.html">Quark Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/export/quark_export_oga.html">ONNX Runtime Gen AI Model Builder</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/quark_torch_best_practices.html">Best Practices for Post-Training Quantization (PTQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/debug.html">Debugging quantization Degradation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/llm_quark.html">Language Model Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_pruning.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_ptq.html">Language Model Post Training Quantization (PTQ) Using Quark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_qat.html">Language Model QAT Using Quark</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval.html">Language Model Evaluations in Quark</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pytorch/example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/tutorial_rotation.html">Quantizing with Rotation and SmoothQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/tutorial_quarot.html">Rotation-based quantization with QuaRot</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/smoothquant.html">Activation/Weight Smoothing (SmoothQuant)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/tutorial_bfp16.html">Block Floating Point 16</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/extensions.html">Extensions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytorch/example_quark_torch_brevitas.html">Brevitas Integration</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/adv_mx.html">Using MX (Microscaling)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/adv_two_level.html">Two Level Quantization Formats</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Quark Features for ONNX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../onnx/user_guide_config_description.html">Configuring ONNX Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/appendix_full_quant_config_features.html">Full List of Quantization Config Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/config/calibration_methods.html">Calibration methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/config/calibration_datasets.html">Calibration datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/config/quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/config/quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/config/quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/user_guide_supported_optype_datatype.html">Data and OP Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/gpu_usage_guide.html">Accelerate with GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/tutorial_mix_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/bfp16.html">Block Floating Point 16 (BFP16)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/tutorial_bf16_quantization.html">BF16 Quantization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../onnx/accuracy_improvement_algorithms.html">Accuracy Improvement Algorithms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/accuracy_algorithms/cle.html">Quantizing Using CrossLayerEqualization (CLE)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/accuracy_algorithms/ada.html">Quantization Using AdaQuant and AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/accuracy_algorithms/sq.html">SmoothQuant (SQ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../onnx/example_quark_onnx_gptq.html">Quantizating a model with GPTQ</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/optional_utilities.html">Optional Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/tools.html">Tools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">APIs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../pytorch/pytorch_apis.html">PyTorch APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/pruning/api/index.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/export/api/index.html">Export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/pruning/config/index.html">Pruner Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/quantization/config/config/index.html">Quantizer Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/torch/export/config/config/index.html">Exporter Configuration</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../onnx/onnx_apis.html">ONNX APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/optimize/index.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/calibrate/index.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/onnx_quantizer/index.html">ONNX Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/qdq_quantizer/index.html">QDQ Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/quantization/config/config/index.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autoapi/quark/onnx/quant_utils/index.html">Quantization Utilities</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Troubleshooting and Support</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../pytorch/pytorch_faq.html">PyTorch FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../onnx/onnx_faq.html">ONNX FAQ</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-angle-right"></span>
  </label></div>
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">quark.onnx.tools.save_tensor_hist</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for quark.onnx.tools.save_tensor_hist</h1><div class="highlight"><pre>
<span></span>#
# Copyright (C) 2023, Advanced Micro Devices, Inc. All rights reserved.
# SPDX-License-Identifier: MIT
#
&#39;&#39;&#39;
A tool for showing the activation distribution of a model.

    Example : python -m quark.onnx.tools.save_tensor_hist --input_model [INPUT_MODEL_PATH] --data_path [CALIB_DATA_PATH]  --output_path [OUTPUT_PATH]

&#39;&#39;&#39;

import os
from quark.shares.utils.log import ScreenLogger
import argparse
import numpy as np
import onnx
import tempfile
import pathlib
import onnxruntime as ort
import matplotlib.pyplot as plt
from pathlib import Path
from tqdm import tqdm

from quark.onnx.calibrate import create_calibrator_float_scale
from quark.onnx.quant_utils import (CachedDataReader, RandomDataReader, check_and_create_path)
from onnxruntime.quantization.calibrate import (CalibrationDataReader, CalibrationMethod, CalibraterBase)

from typing import List, Dict, Any, Optional, Iterator
from numpy.typing import NDArray

logger = ScreenLogger(__name__)

preprocess_range = &quot;[-1,1]&quot;


# Raw data means binary format which had been pre-processed
def load_raw_data(data_path: str, file_names: List[str], input_shape: List[int]) -&gt; Dict[str, NDArray[np.float32]]:
    data_dict = {}
    for file_name in file_names:
        with open(os.path.join(data_path, file_name), &quot;rb&quot;) as f:
            raw_data = f.read()
            data_array = np.frombuffer(raw_data, dtype=np.float32)
            data_dict[file_name] = np.reshape(data_array, input_shape)
    return data_dict


# Npy data means the data was stored in numpy array format
def load_npy_data(data_path: str, file_names: List[str], input_shape: List[int]) -&gt; Dict[str, NDArray[Any]]:
    data_dict = {}
    for file_name in file_names:
        npy_data = np.load(os.path.join(data_path, file_name))
        npy_data = npy_data.transpose(1, 2, 0)
        input_data = np.expand_dims(npy_data, axis=0)
        assert (list(input_data.shape) == input_shape
                and &quot;{} data shape {} does not match expected {}&quot;.format(file_name, input_data.shape, input_shape))
        data_dict[file_name] = input_data
    return data_dict


# Img data means image files and need pre-processing
# - Loaded image&#39;s shape : (H, W, C)
# - Model input&#39;s shape : [N, C, H, W] or [N, H, W, C]
def load_img_data(data_path: str, file_names: List[str], input_shape: List[int]) -&gt; Dict[str, NDArray[np.float32]]:
    import cv2
    print(f&quot;load image data and pre-process with range {preprocess_range} expected shape {input_shape}&quot;)

    data_dict = {}

    for file_name in file_names:
        img_data = cv2.imread(os.path.join(data_path, file_name))

        if input_shape[3] == 3:
            input_shape_copy = [input_shape[0], input_shape[3], input_shape[1],
                                input_shape[2]]  # [N, H, W, C] -&gt; [N, C, H, W]
        else:
            input_shape_copy = input_shape  # [N, C, H, W]

        if (img_data.shape[0] != input_shape_copy[2] or img_data.shape[1] != input_shape_copy[3]):
            img_data = cv2.resize(img_data, (input_shape_copy[2], input_shape_copy[3]))

        if input_shape[1] == 3:
            img_data = img_data.transpose(2, 0, 1)
        input_data = img_data.astype(np.float32)
        input_data = np.expand_dims(input_data, axis=0)

        if preprocess_range == &quot;[-1,1]&quot;:
            input_data = (input_data / 255. - 0.5) * 2.
        elif preprocess_range == &quot;[0,1]&quot;:
            input_data = input_data / 255.

        data_dict[file_name] = input_data

    return data_dict


# Used PIL instead of opencv
def load_img_data2(data_path: str, file_names: List[str], input_shape: List[int]) -&gt; Dict[str, NDArray[np.float32]]:
    from PIL import Image
    print(f&quot;load image data and pre-process with range {preprocess_range} expected shape {input_shape}&quot;)

    data_dict = {}

    for file_name in file_names:
        input_image = Image.open(os.path.join(data_path, file_name))

        if input_shape[3] == 3:
            input_shape_copy = [input_shape[0], input_shape[3], input_shape[1],
                                input_shape[2]]  # [N, H, W, C] -&gt; [N, C, H, W]
        else:
            input_shape_copy = input_shape  # [N, C, H, W]

        if (input_image.size[1] != input_shape_copy[2] or  # Image.size = (W, H)
                input_image.size[0] != input_shape_copy[3]):
            input_image_new = input_image.resize((input_shape_copy[2], input_shape_copy[3]))

        input_data = np.array(input_image_new).astype(np.float32)
        if input_shape[1] == 3:
            input_data = input_data.transpose(2, 0, 1)
        input_data = np.expand_dims(input_data, axis=0)

        if preprocess_range == &quot;[-1,1]&quot;:
            input_data = (input_data / 255. - 0.5) * 2.
        elif preprocess_range == &quot;[0,1]&quot;:
            input_data = input_data / 255.

        data_dict[file_name] = input_data

    return data_dict


# Load data from data path and support raw data, npy data and image data,
# return a dict, key is file name and value is numpy arrary
def load_data(data_path: str, input_shape: List[int]) -&gt; Dict[str, NDArray[np.float32]]:
    files = [f for f in os.listdir(data_path) if (f.endswith(&#39;.png&#39;) or f.endswith(&#39;.jpg&#39;))]
    if files != []:
        print(&quot;Loading image data from {}&quot;.format(data_path))
        return load_img_data2(data_path, files, input_shape)
    else:
        files = [f for f in os.listdir(data_path) if f.endswith(&#39;.npy&#39;)]
        if files != []:
            print(&quot;Loading npy data from {}&quot;.format(data_path))
            return load_npy_data(data_path, files, input_shape)
        else:
            files = [
                f for f in os.listdir(data_path) if (f.endswith(&#39;.bin&#39;) or f.endswith(&#39;.raw&#39;) or f.endswith(&#39;.data&#39;))
            ]
            if files != []:
                print(&quot;Loading raw data from {}&quot;.format(data_path))
                return load_raw_data(data_path, files, input_shape)
            else:
                raise RuntimeError(&quot;Not found data in {}&quot;.format(data_path))


# Load raw data according to input name
def load_raw_data_by_input_name(data_path: str, file_names: List[str], input_shape: List[int], model_path: str,
                                input_name: str) -&gt; Dict[str, NDArray[np.float32]]:
    origin_name = input_name

    data_dict = {}
    for file_name in file_names:
        if len(file_name) &gt; len(origin_name) and file_name[0:len(origin_name)] == origin_name and file_name[len(
                origin_name)] == &quot;_&quot;:
            with open(os.path.join(data_path, file_name), &quot;rb&quot;) as f:
                raw_data = f.read()
                data_array = np.frombuffer(raw_data, dtype=np.float32)
                data_dict[file_name[len(origin_name):]] = np.reshape(data_array, input_shape)
    return data_dict


# Load data according to input name
def load_data_by_input_name(data_path: str, input_shape: List[int], model_path: str,
                            input_name: str) -&gt; Dict[str, NDArray[np.float32]]:
    files = [f for f in os.listdir(data_path) if (f.endswith(&#39;.bin&#39;) or f.endswith(&#39;.raw&#39;) or f.endswith(&#39;.data&#39;))]
    if files != []:
        print(&quot;Loading raw data from {} for input {}&quot;.format(data_path, input_name))
        return load_raw_data_by_input_name(data_path, files, input_shape, model_path, input_name)
    else:
        raise RuntimeError(&quot;Not found data in {} for input {}&quot;.format(data_path, input_name))


<div class="viewcode-block" id="HistDataReader">
<a class="viewcode-back" href="../../../../autoapi/quark/onnx/tools/save_tensor_hist/index.html#quark.onnx.tools.save_tensor_hist.HistDataReader">[docs]</a>
class HistDataReader(RandomDataReader):

    def __init__(self, model_path: str, data_path: str, input_shape: Dict[str, List[int]] = {}):
        &quot;&quot;&quot;
        :param model_path : Full path of the input model.
        :param data_path  : Full path of the input data.
        :param input_shape: If dynamic axes of inputs require specific value, users should provide its shapes.
                            The basic format of shape for single input is `list(int)` or `tuple(int)`,
                            and all dimensions should have concrete values (batch dimensions can be set to 1).
                            For example, input_shape=[1, 3, 224, 224] or input_shape=(1, 3, 224, 224).
                            If the model has multiple inputs, it can be fed in `list(shape)` format,
                            where the list order is the same as the onnxruntime got inputs.
                            For example, input_shape=[[1, 1, 224, 224], [1, 2, 224, 224]] for 2 inputs.
                            Moreover, it is possible to use `dict{name:shape}` to specify a certain input,
                            for example, input_shape={&quot;image&quot;:[1, 3, 224, 224]} for the input named &quot;image&quot;.
        &quot;&quot;&quot;

        self._data_path = data_path
        self.enum_data_iter: Optional[Iterator[Dict[str, NDArray[np.float32]]]] = None
        self.data_dict: Dict[str, List[NDArray[np.float32]]] = {}
        super().__init__(model_path, input_shape)

<div class="viewcode-block" id="HistDataReader.get_next">
<a class="viewcode-back" href="../../../../autoapi/quark/onnx/tools/save_tensor_hist/index.html#quark.onnx.tools.save_tensor_hist.HistDataReader.get_next">[docs]</a>
    def get_next(self) -&gt; Optional[Dict[str, NDArray[np.float32]]]:
        &quot;&quot;&quot;
        Get next feed data
        :return: feed dict for the model
        &quot;&quot;&quot;
        if self.enum_data_iter is None:
            so = ort.SessionOptions()
            session = ort.InferenceSession(self._model_path, so, providers=[&#39;CPUExecutionProvider&#39;])

            for input_index, input_node in enumerate(session.get_inputs()):
                input_name = self._get_input_name(input_node)
                input_shape = self._parse_input_shape(input_index, input_name)
                if input_shape == [] or input_shape is None:
                    input_shape = self._get_input_shape(input_node)
                input_type = self._get_input_type(input_node)

                # load data from data path
                data_dict: Dict[str, NDArray[np.float32]] = {}

                if len(session.get_inputs()) &gt; 1 or len(  # for audio models
                        session.get_outputs()) &gt;= 5:  # for model K1
                    data_dict = load_data_by_input_name(self._data_path, input_shape, self._model_path, input_name)
                else:
                    data_dict = load_data(self._data_path, input_shape)

                if len(data_dict) &lt;= 0:
                    raise RuntimeError(&quot;Load data from the path {} failed for input{} {}&quot;.format(
                        self._data_path, input_index, input_name))
                else:
                    print(&quot;Load data from the path {} for input{} with {} samples &quot;.format(
                        self._data_path, input_index, len(data_dict)))

                # save to data_dict
                for key, value in data_dict.items():
                    if value.dtype is not input_type:
                        value = value.astype(input_type)
                    if key in self.data_dict:
                        self.data_dict[key].append(value)
                    else:
                        self.data_dict[key] = [value]

                print(&quot;Real input name {} shape {} type {} &quot;.format(input_name, input_shape, input_type))

            self.enum_data_list = []

            for arrays in self.data_dict.values():
                enum_data = {}
                for i, arr in enumerate(arrays):
                    name = self._get_input_name(session.get_inputs()[i])
                    enum_data[name] = arr
                self.enum_data_list.append(enum_data)

            self.enum_data_iter = iter(self.enum_data_list)

        return next(self.enum_data_iter, None)</div>
</div>



def save_figure(calibrator: CalibraterBase, saved_path: Optional[str] = None) -&gt; None:
    if saved_path is None:
        saved_path = &quot;./&quot;

    print(&quot;The tensors hist saved path: {}&quot;.format(saved_path))

    # Initialize tqdm progress bar
    progress_bar = tqdm(total=len(calibrator.collector.histogram_dict), desc=&quot;Saving Histograms&quot;)

    for tensor_name, tensor_value in calibrator.collector.histogram_dict.items():
        # Replace the tensor_name
        tensor_name = tensor_name.replace(&quot;/&quot;, &quot;_&quot;)
        tensor_name = tensor_name.replace(&quot;.&quot;, &quot;_&quot;)
        tensor_name = tensor_name.replace(&quot;:&quot;, &quot;_&quot;)

        # Extract histogram data
        tensor_freq = tensor_value[0]
        tensor_bins = tensor_value[1]

        # Plot the histogram
        bar_width = tensor_bins[1] - tensor_bins[0]
        plt.bar(tensor_bins[:-1], tensor_freq, width=bar_width)
        plt.text(tensor_bins[-1], tensor_freq[-1], str(tensor_freq[-1]), ha=&#39;center&#39;, va=&#39;bottom&#39;)

        # Construct the file path to save the histogram
        model_hist_path = Path(saved_path).joinpath(tensor_name + &quot;.png&quot;).as_posix()

        # Add title and labels
        plt.title(tensor_name)
        plt.xlabel(&#39;Values&#39;)
        plt.ylabel(&#39;Frequency&#39;)

        # Save the histogram
        plt.savefig(model_hist_path)

        # Clear the current figure and close it to release resources
        plt.clf()
        plt.close()

        # Update progress bar
        progress_bar.update(1)

    # Close progress bar
    progress_bar.close()

    print(&quot;The tensor hist saved done&quot;)


# Generate the percentile calibrator
# Collect all data then save tensors to picture
# Reset the DataReader
def save_tensor_hist_figure(input_model_path: str,
                            dr: CalibrationDataReader,
                            output_figure_path: Optional[str] = None) -&gt; None:

    # Need to reload &amp; save the file if the input_model_path does not have write permissions
    origin_input_model = onnx.load(input_model_path)
    tmp_path = tempfile.TemporaryDirectory(prefix=&quot;vai.tools.&quot;)
    tmp_model = Path(tmp_path.name).joinpath(&quot;converted.onnx&quot;).as_posix()
    onnx.save(origin_input_model, tmp_model)
    # Generate the calibrator
    # Need to save the augmented_model.onnx to tmp_path
    calibrator = create_calibrator_float_scale(
        Path(tmp_model),
        None,
        augmented_model_path=Path(tmp_path.name).joinpath(&quot;augmented_model.onnx&quot;).as_posix(),
        calibrate_method=CalibrationMethod.Percentile,
        use_external_data_format=False,
        execution_providers=[&#39;CPUExecutionProvider&#39;],
        extra_options={&quot;symmetric&quot;: False},
    )
    # Warp the DataReader
    cached_data_reader = CachedDataReader(dr)
    # Collect data and save data to histogram_dict
    calibrator.collect_data(cached_data_reader)

    logger.info(&quot;Saving the tensor histogram&quot;)

    save_figure(calibrator, output_figure_path)
    # Reset the CachedDataReader
    cached_data_reader.reset_iter()


# generate the output tensor histogram
def get_tensor_hist() -&gt; None:
    parser = argparse.ArgumentParser(
        f&quot;{os.path.basename(__file__)}:{get_tensor_hist.__name__}&quot;,
        description=&quot;&quot;&quot;
                                    Generated the output tensor histogram
                                    Provide input_model path and DataReader path, output_path&quot;&quot;&quot;,
    )

    parser.add_argument(&quot;--input_model&quot;,
                        type=pathlib.Path,
                        help=&quot;Provide path to ONNX model to generate histogram.&quot;,
                        required=True)

    parser.add_argument(&quot;--data_path&quot;, type=pathlib.Path, help=&quot;Provide the data reader path.&quot;, required=True)

    parser.add_argument(&quot;--output_path&quot;, type=pathlib.Path, help=&quot;Provide path to write histogram figure.&quot;)

    args = parser.parse_args()

    abs_path = check_and_create_path(args.output_path)

    # generate the default DataReader
    dr = HistDataReader(args.input_model, args.data_path, {})

    save_tensor_hist_figure(args.input_model, dr, abs_path)


if __name__ == &#39;__main__&#39;:
    get_tensor_hist()
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            <p>
      Last updated on Feb 12, 2025.<br/>
  </p>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

<footer class="rocm-footer">
    <div class="container-lg">
        <section class="bottom-menu menu py-45">
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <ul>
                        <li><a href="https://www.amd.com/en/corporate/copyright" target="_blank">Terms and Conditions</a></li>
                        <li><a href="https://quark.docs.amd.com/latest/license.html">Quark Licenses and Disclaimers</a></li>
                        <li><a href="https://www.amd.com/en/corporate/privacy" target="_blank">Privacy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/trademarks" target="_blank">Trademarks</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf" target="_blank">Statement on Forced Labor</a></li>
                        <li><a href="https://www.amd.com/en/corporate/competition" target="_blank">Fair and Open Competition</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf" target="_blank">UK Tax Strategy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/cookies" target="_blank">Cookie Policy</a></li>
                        <!-- OneTrust Cookies Settings button start -->
                        <li><a href="#cookie-settings" id="ot-sdk-btn" class="ot-sdk-show-settings">Cookie Settings</a></li>
                        <!-- OneTrust Cookies Settings button end -->
                    </ul>
                </div>
            </div>
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <div>
                        <span class="copyright">© 2024 Advanced Micro Devices, Inc</span>
                    </div>
                </div>
            </div>
        </section>
    </div>
</footer>

<!-- <div id="rdc-watermark-container">
    <img id="rdc-watermark" src="../../../../_static/images/alpha-watermark.svg" alt="DRAFT watermark"/>
</div> -->
  </body>
</html>