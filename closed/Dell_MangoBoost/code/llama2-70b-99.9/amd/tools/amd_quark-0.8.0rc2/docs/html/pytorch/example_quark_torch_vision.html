
<!DOCTYPE html>


<html lang="en" data-content_root="../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>Vision Model Quantization Using Quark FX Graph Mode &#8212; Quark 0.8.0rc2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css?v=6b4ca4e1" />
    <link rel="stylesheet" type="text/css" href="../_static/rocm_header.css?v=4044f309" />
    <link rel="stylesheet" type="text/css" href="../_static/rocm_footer.css?v=25204c5a" />
    <link rel="stylesheet" type="text/css" href="../_static/fonts.css?v=fcff5274" />
  
  <!-- So that users can add custom icons -->
  <script src="../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../_static/documentation_options.js?v=d42b94c0"></script>
    <script src="../_static/doctools.js?v=9bcbadda"></script>
    <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="../_static/code_word_breaks.js?v=327952c4"></script>
    <script async="async" src="../_static/renameVersionLinks.js?v=929fe5e4"></script>
    <script async="async" src="../_static/rdcMisc.js?v=01f88d96"></script>
    <script async="async" src="../_static/theme_mode_captions.js?v=15f4ec5d"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'pytorch/example_quark_torch_vision';</script>
    <script async="async" src="https://download.amd.com/js/analytics/analyticsinit.js"></script>
    <link rel="icon" href="https://www.amd.com/themes/custom/amd/favicon.ico"/>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Accessing ONNX Examples" href="../onnx/onnx_examples.html" />
    <link rel="prev" title="LM-Evaluation Harness (Offline)" href="example_quark_torch_llm_eval_harness_offline.html" />
<script type="text/javascript">
    window.addEventListener("load", function(event) {
        var coll = document.querySelectorAll('.toggle > .header');  // sdelect the toggles header.
        var i;

        for (i = 0; i < coll.length; i++) {                        
            coll[i].innerText = "Show code ▼\n\n";
            
            coll[i].addEventListener("click", function() {
                var content = this.nextElementSibling;  // code block.
                if (content.style.display === "block") {
                    content.style.display = "none";
                    this.innerText = "Show code ▼\n\n";
                } else {
                    content.style.display = "block";
                    this.innerText = "Hide code ▶";
                }
            });
        }
    });
</script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  

<header class="common-header" >
    <nav class="navbar navbar-expand-xl">
        <div class="container-fluid main-nav rocm-header">
            
            <button class="navbar-toggler collapsed" id="nav-icon" data-tracking-information="mainMenuToggle" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="header-logo">
                <a class="navbar-brand" href="https://www.amd.com/">
                    <img src="../_static/images/amd-header-logo.svg" alt="AMD Logo" title="AMD Logo" width="90" class="d-inline-block align-text-top hover-opacity"/>
                </a>
                <div class="vr vr mx-40 my-25"></div>
                <a class="klavika-font hover-opacity" href="https://quark.docs.amd.com">Quark</a>
                <a class="header-all-versions" href="https://quark.docs.amd.com/latest/versions.html">Version List</a>
            </div>
            <div class="icon-nav text-center d-flex ms-auto">
            </div>
        </div>
    </nav>
    
    <nav class="navbar navbar-expand-xl second-level-nav">
        <div class="container-fluid main-nav">
            <div class="navbar-nav-container collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-mega me-auto mb-2 mb-lg-0 col-xl-10">
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark" id="navgithub" role="button" aria-expanded="false" target="_blank" >
                                GitHub
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark/issues/new/choose" id="navsupport" role="button" aria-expanded="false" target="_blank" >
                                Support
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
    </nav>
    
</header>


  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Quark 0.8.0rc2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../release_note.html">Release Information</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started with AMD Quark</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction to Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../install.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../basic_usage.html">Basic Usage</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="basic_usage_pytorch.html">AMD Quark for PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/basic_usage_onnx.html">AMD Quark for ONNX</a></li>
</ul>
</details></li>
<li class="toctree-l1 current active has-children"><a class="reference internal" href="pytorch_examples.html">Accessing PyTorch Examples</a><details open="open"><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_diffusers.html">Diffusion Model Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_brevitas.html">AMD Quark Extension for Brevitas Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_pruning.html">Language Model Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_ptq.html">Language Model PTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_qat.html">Language Model QAT</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="example_quark_torch_llm_eval.html">Language Model Evaluation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2 current active"><a class="current reference internal" href="#">Vision Model Quantization using FX Graph Mode</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../onnx/onnx_examples.html">Accessing ONNX Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_BFP.html">Block Floating Point (BFP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_MX.html">MX Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_adaround.html">Fast Finetune AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_adaquant.html">Fast Finetune AdaQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_cle.html">Cross-Layer Equalization (CLE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_gptq.html">GPTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_smoothquant.html">Smooth Quant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_quarot.html">QuaRot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_dynamic_quantization_llama2.html">Quantizing an Llama-2-7b Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_dynamic_quantization_opt.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_image_classification.html">Quantizing a ResNet50-v1-12 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_language_models.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_weights_only_quant_int4_matmul_nbits_llama2.html">Quantizing an Llama-2-7b Model Using the ONNX MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_weights_only_quant_int8_qdq_llama2.html">Quantizating Llama-2-7b model using MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/image_classification_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Image Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/object_detection_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Object Detection Model</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced AMD Quark Features for PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="user_guide_config_description.html">Configuring PyTorch Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="calibration_methods.html">Calibration Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="calibration_datasets.html">Calibration Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="quark_save_load.html">Save and Load Quantized Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="export/quark_export.html">Exporting Quantized Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="export/quark_export_onnx.html">ONNX Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="export/quark_export_hf.html">HuggingFace Format</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="export/quark_export_gguf.html">GGUF Format</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="export/gguf_llamacpp.html">Bridge from Quark to llama.cpp</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="export/quark_export_quark.html">Quark Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="export/quark_export_oga.html">ONNX Runtime Gen AI Model Builder</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="quark_torch_best_practices.html">Best Practices for Post-Training Quantization (PTQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="debug.html">Debugging quantization Degradation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="llm_quark.html">Language Model Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_pruning.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_ptq.html">Language Model Post Training Quantization (PTQ) Using Quark</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_llm_qat.html">Language Model QAT Using Quark</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="example_quark_torch_llm_eval.html">Language Model Evaluations in Quark</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_rotation.html">Quantizing with Rotation and SmoothQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="tutorial_quarot.html">Rotation-based quantization with QuaRot</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="smoothquant.html">Activation/Weight Smoothing (SmoothQuant)</a></li>
<li class="toctree-l1"><a class="reference internal" href="tutorial_bfp16.html">Block Floating Point 16</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="extensions.html">Extensions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="example_quark_torch_brevitas.html">Brevitas Integration</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="adv_mx.html">Using MX (Microscaling)</a></li>
<li class="toctree-l1"><a class="reference internal" href="adv_two_level.html">Two Level Quantization Formats</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Quark Features for ONNX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../onnx/user_guide_config_description.html">Configuring ONNX Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../onnx/appendix_full_quant_config_features.html">Full List of Quantization Config Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/config/calibration_methods.html">Calibration methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/config/calibration_datasets.html">Calibration datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/config/quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/config/quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/config/quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/user_guide_supported_optype_datatype.html">Data and OP Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/gpu_usage_guide.html">Accelerate with GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/tutorial_mix_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/bfp16.html">Block Floating Point 16 (BFP16)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/tutorial_bf16_quantization.html">BF16 Quantization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../onnx/accuracy_improvement_algorithms.html">Accuracy Improvement Algorithms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../onnx/accuracy_algorithms/cle.html">Quantizing Using CrossLayerEqualization (CLE)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../onnx/accuracy_algorithms/ada.html">Quantization Using AdaQuant and AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/accuracy_algorithms/sq.html">SmoothQuant (SQ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../onnx/example_quark_onnx_gptq.html">Quantizating a model with GPTQ</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/optional_utilities.html">Optional Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/tools.html">Tools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">APIs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="pytorch_apis.html">PyTorch APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/pruning/api/index.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/export/api/index.html">Export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/pruning/config/index.html">Pruner Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/quantization/config/config/index.html">Quantizer Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/torch/export/config/config/index.html">Exporter Configuration</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../onnx/onnx_apis.html">ONNX APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/optimize/index.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/calibrate/index.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/onnx_quantizer/index.html">ONNX Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/qdq_quantizer/index.html">QDQ Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/quantization/config/config/index.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../autoapi/quark/onnx/quant_utils/index.html">Quantization Utilities</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Troubleshooting and Support</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="pytorch_faq.html">PyTorch FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../onnx/onnx_faq.html">ONNX FAQ</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-angle-right"></span>
  </label></div>
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="pytorch_examples.html" class="nav-link">Accessing PyTorch Examples</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">Vision Model Quantization Using Quark FX Graph Mode</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>
<button class="sidebar-toggle secondary-toggle btn btn-sm" title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</button>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Vision Model Quantization Using Quark FX Graph Mode</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-example-code-and-script">Get example code and script</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ptq">PTQ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qat">QAT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tqt">TQT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-start">Quick Start</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-grained-user-guide">Fine-Grained User Guide</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-results">Experiment Results</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification-task-ptq-qat-results">1. Image Classification Task PTQ/QAT Results</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#object-detection-task-ptq-qat-results">2. Object Detection Task PTQ/QAT Results</a></li>
</ul>
</li>
</ul>
</li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section id="vision-model-quantization-using-quark-fx-graph-mode">
<h1>Vision Model Quantization Using Quark FX Graph Mode<a class="headerlink" href="#vision-model-quantization-using-quark-fx-graph-mode" title="Link to this heading">#</a></h1>
<p>This example demonstrates a vision model quantization workflow. You specify a <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> and transform the model to <code class="docutils literal notranslate"><span class="pre">torch.fx.GraphModule</span></code> format using the PyTorch API. During the quantization process, after annotation and insertion of quantizers, this modified <code class="docutils literal notranslate"><span class="pre">fx.GraphModule</span></code> can be used to perform PTQ (Post-Training Quantization) and/or QAT (Quantization Aware Training). Demonstration code is provided to show how you can assign <code class="docutils literal notranslate"><span class="pre">quant</span> <span class="pre">config</span></code>.</p>
<p>In this example, we present a vision model quantization workflow. The
user specified a <code class="docutils literal notranslate"><span class="pre">nn.Module</span></code> and transformed the model to
<code class="docutils literal notranslate"><span class="pre">torch.fx.GraphModule</span></code> format by using PyTorch API. During the
quantization process, after annotation and insertion quantizers, this
modified <code class="docutils literal notranslate"><span class="pre">fx.GraphModule</span></code> can be used to perform PTQ (Post Training
Quantization), or/and QAT (Quantization Aware Training). We supply a
demonstration code and show how users assign <code class="docutils literal notranslate"><span class="pre">quant</span> <span class="pre">config</span></code>, more
information can be found in User Guide.</p>
<section id="get-example-code-and-script">
<h2>Get example code and script<a class="headerlink" href="#get-example-code-and-script" title="Link to this heading">#</a></h2>
<p>After unzip <code class="docutils literal notranslate"><span class="pre">amd_quark.zip</span></code> (referring to <a class="reference internal" href="../install.html"><span class="doc">Installation Guide</span></a>).
The example folder is in amd_quark.zip. In folder <code class="docutils literal notranslate"><span class="pre">/examples/torch/vision</span></code>, user can get the detailed explanation of
image classification and object detection quantization demonstration code.
.. note:</p>
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>For information on accessing Quark PyTorch examples, refer to `Accessing PyTorch Examples &lt;pytorch_examples&gt;`_.
This example and the relevant files are available at ``/torch/vision``.
</pre></div>
</div>
</section>
<section id="ptq">
<h2>PTQ<a class="headerlink" href="#ptq" title="Link to this heading">#</a></h2>
<p>In Post-Training Quantization (PTQ), after inserting <code class="docutils literal notranslate"><span class="pre">FakeQuantize</span></code>, the <code class="docutils literal notranslate"><span class="pre">observer</span></code> is activated during calibration to record the tensor’s distribution. Values such as minimum and maximum are recorded to calculate quantization parameters, without performing fake quantization. This ensures all calculations are under FP32 precision. After calibration, you can activate the fake quantizer to perform quantization and evaluation.</p>
</section>
<section id="qat">
<h2>QAT<a class="headerlink" href="#qat" title="Link to this heading">#</a></h2>
<p>Similar to Post-Training Quantization (PTQ), after preparing the model, both the <code class="docutils literal notranslate"><span class="pre">observer</span></code> and <code class="docutils literal notranslate"><span class="pre">fake_quant</span></code> are active during the training process. The <code class="docutils literal notranslate"><span class="pre">observer</span></code> records the tensor’s distribution, including minimum and maximum values, to calculate quantization parameters. The tensor is then quantized by <code class="docutils literal notranslate"><span class="pre">fake_quant</span></code>.</p>
</section>
<section id="tqt">
<h2>TQT<a class="headerlink" href="#tqt" title="Link to this heading">#</a></h2>
<p>This method involves uniform symmetric quantizers using standard backpropagation and gradient descent. Unlike Quantization-Aware Training (QAT), Trained Quantization Thresholds (TQT) add a gradient for scale factors. Unlike Learned Step Size Quantization (LSQ), which directly trains scale factors and may encounter stability issues, TQT constrains scale factors to powers of two and uses a gradient formulation to train log-thresholds instead. Theoretically, TQT is superior to LSQ, and LSQ is superior to QAT. For efficient fixed-point implementations, TQT constrains the quantization scheme to use symmetric quantization, per-tensor scaling, and power-of-two scaling. Currently, TQT supports only signed data. More experimental results are forthcoming.</p>
<section id="quick-start">
<h3>Quick Start<a class="headerlink" href="#quick-start" title="Link to this heading">#</a></h3>
<p>Perform Post-Training Quantization (PTQ) to obtain the quantized model and export it to ONNX:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>quantize.py<span class="w"> </span>--data_dir<span class="w"> </span><span class="o">[</span>Train<span class="w"> </span>and<span class="w"> </span>Test<span class="w"> </span>Data<span class="w"> </span>folder<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--model_name<span class="w"> </span><span class="o">[</span>mobilenetv2<span class="w"> </span>or<span class="w"> </span>resnet18<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--pretrained<span class="w"> </span><span class="o">[</span>Pre-trained<span class="w"> </span>model<span class="w"> </span>file<span class="w"> </span>address<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--model_export<span class="w"> </span>onnx<span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--export_dir<span class="w"> </span><span class="o">[</span>directory<span class="w"> </span>to<span class="w"> </span>save<span class="w"> </span>exported<span class="w"> </span>model<span class="o">]</span>
</pre></div>
</div>
<p>You can also choose to perform Quantization-Aware Training (QAT) to further enhance classification accuracy. Typically, some training parameters need to be adjusted for higher accuracy:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>python3<span class="w"> </span>quantize.py<span class="w"> </span>--data_dir<span class="w"> </span><span class="o">[</span>Train<span class="w"> </span>and<span class="w"> </span>Test<span class="w"> </span>Data<span class="w"> </span>folder<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--model_name<span class="w"> </span><span class="o">[</span>mobilenetv2<span class="w"> </span>or<span class="w"> </span>resnet18<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--pretrained<span class="w"> </span><span class="o">[</span>Pre-trained<span class="w"> </span>model<span class="w"> </span>file<span class="w"> </span>address<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--model_export<span class="w"> </span>onnx<span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--export_dir<span class="w"> </span><span class="o">[</span>directory<span class="w"> </span>to<span class="w"> </span>save<span class="w"> </span>exported<span class="w"> </span>model<span class="o">]</span><span class="w"> </span><span class="se">\</span>
<span class="w">                    </span>--qat<span class="w"> </span>True
</pre></div>
</div>
<p>LSQ and TQT are optimized methods for QAT that can theoretically improve accuracy. The parameters <code class="docutils literal notranslate"><span class="pre">--tqt</span> <span class="pre">True</span></code> and <code class="docutils literal notranslate"><span class="pre">--lsq</span> <span class="pre">True</span></code> are available for you to try. Model export is not supported at this time.</p>
</section>
<section id="fine-grained-user-guide">
<h3>Fine-Grained User Guide<a class="headerlink" href="#fine-grained-user-guide" title="Link to this heading">#</a></h3>
<p><strong>Step 1: Prepare the floating-point model, dataset, and loss function</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torchvision.models</span><span class="w"> </span><span class="kn">import</span> <span class="n">resnet18</span>
<span class="n">float_model</span> <span class="o">=</span> <span class="n">resnet18</span><span class="p">(</span><span class="n">pretrained</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">float_model</span><span class="o">.</span><span class="n">load_state_dict</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">pretrained</span><span class="p">))</span>
<span class="n">calib_loader</span> <span class="o">=</span> <span class="n">prepare_calib_dataset</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_dir</span><span class="p">,</span> <span class="n">device</span><span class="p">,</span> <span class="n">calib_length</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">train_batch_size</span> <span class="o">*</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span> <span class="o">=</span> <span class="n">prepare_data_loaders</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">data_dir</span><span class="p">)</span>
<span class="n">criterion</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">CrossEntropyLoss</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 2: Transform the ``torch.nn.Module`` to ``torch.fx.GraphModule``</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">torch._export</span><span class="w"> </span><span class="kn">import</span> <span class="n">capture_pre_autograd_graph</span>
<span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">train_batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="p">)</span>
<span class="n">graph_model</span> <span class="o">=</span> <span class="n">capture_pre_autograd_graph</span><span class="p">(</span><span class="n">float_model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 3: Initialize the quantizer and quantization configuration</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span><span class="w"> </span><span class="nn">quark.torch.quantization.config.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">QuantizationSpec</span><span class="p">,</span> <span class="n">QuantizationConfig</span><span class="p">,</span> <span class="n">Config</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">quark.torch.quantization.config.type</span><span class="w"> </span><span class="kn">import</span> <span class="n">Dtype</span><span class="p">,</span> <span class="n">QSchemeType</span><span class="p">,</span> <span class="n">ScaleType</span><span class="p">,</span> <span class="n">RoundType</span><span class="p">,</span> <span class="n">QuantizationMode</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">quark.torch.quantization.observer.observer</span><span class="w"> </span><span class="kn">import</span> <span class="n">PerTensorMinMaxObserver</span>
<span class="n">INT8_PER_TENSOR_SPEC</span> <span class="o">=</span> <span class="n">QuantizationSpec</span><span class="p">(</span><span class="n">dtype</span><span class="o">=</span><span class="n">Dtype</span><span class="o">.</span><span class="n">int8</span><span class="p">,</span>
                                        <span class="n">qscheme</span><span class="o">=</span><span class="n">QSchemeType</span><span class="o">.</span><span class="n">per_tensor</span><span class="p">,</span>
                                        <span class="n">observer_cls</span><span class="o">=</span><span class="n">PerTensorMinMaxObserver</span><span class="p">,</span>
                                        <span class="n">symmetric</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
                                        <span class="n">scale_type</span><span class="o">=</span><span class="n">ScaleType</span><span class="o">.</span><span class="n">float</span><span class="p">,</span>
                                        <span class="n">round_method</span><span class="o">=</span><span class="n">RoundType</span><span class="o">.</span><span class="n">half_even</span><span class="p">,</span>
                                        <span class="n">is_dynamic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">quant_config</span> <span class="o">=</span> <span class="n">QuantizationConfig</span><span class="p">(</span><span class="n">input_tensors</span><span class="o">=</span><span class="n">INT8_PER_TENSOR_SPEC</span><span class="p">,</span>
                                      <span class="n">output_tensors</span><span class="o">=</span><span class="n">INT8_PER_TENSOR_SPEC</span><span class="p">,</span>
                                      <span class="n">weight</span><span class="o">=</span><span class="n">INT8_PER_TENSOR_SPEC</span><span class="p">,</span>
                                      <span class="n">bias</span><span class="o">=</span><span class="n">INT8_PER_TENSOR_SPEC</span><span class="p">)</span>
<span class="n">quant_config</span> <span class="o">=</span> <span class="n">Config</span><span class="p">(</span><span class="n">global_quant_config</span><span class="o">=</span><span class="n">quant_config</span><span class="p">,</span>
                      <span class="n">quant_mode</span><span class="o">=</span><span class="n">QuantizationMode</span><span class="o">.</span><span class="n">fx_graph_mode</span><span class="p">)</span>
<span class="n">quantizer</span> <span class="o">=</span> <span class="n">ModelQuantizer</span><span class="p">(</span><span class="n">quant_config</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 4: Generate the quantized graph model by performing calibration</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">quantized_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">quantize_model</span><span class="p">(</span><span class="n">graph_model</span><span class="p">,</span> <span class="n">calib_loader</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 5 (Optional): Perform QAT for higher accuracy</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">train</span><span class="p">(</span><span class="n">quantized_model</span><span class="p">,</span> <span class="n">train_loader</span><span class="p">,</span> <span class="n">val_loader</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device_ids</span><span class="p">)</span>
</pre></div>
</div>
<p><strong>Step 6: Validate model performance and export</strong></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">acc1_quant</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">quantized_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="n">freezed_model</span> <span class="o">=</span> <span class="n">quantizer</span><span class="o">.</span><span class="n">freeze</span><span class="p">(</span><span class="n">prepared_model</span><span class="p">)</span>
<span class="n">acc1_freeze</span> <span class="o">=</span> <span class="n">validate</span><span class="p">(</span><span class="n">val_loader</span><span class="p">,</span> <span class="n">freezed_model</span><span class="p">,</span> <span class="n">criterion</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>
<span class="c1"># Check whether acc1_quant == acc1_freeze</span>

<span class="c1"># ============== Export to ONNX ==================</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">quark.torch</span><span class="w"> </span><span class="kn">import</span> <span class="n">ModelExporter</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">quark.torch.export.config.config</span><span class="w"> </span><span class="kn">import</span> <span class="n">ExporterConfig</span><span class="p">,</span> <span class="n">JsonExporterConfig</span>
<span class="n">config</span> <span class="o">=</span> <span class="n">ExporterConfig</span><span class="p">(</span><span class="n">json_export_config</span><span class="o">=</span><span class="n">JsonExporterConfig</span><span class="p">())</span>
<span class="n">exporter</span> <span class="o">=</span> <span class="n">ModelExporter</span><span class="p">(</span><span class="n">config</span><span class="o">=</span><span class="n">config</span><span class="p">,</span> <span class="n">export_dir</span><span class="o">=</span><span class="n">args</span><span class="o">.</span><span class="n">export_dir</span><span class="p">)</span>
<span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">rand</span><span class="p">(</span><span class="n">batch_size</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="mi">224</span><span class="p">,</span> <span class="mi">224</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),)</span>
<span class="n">exporter</span><span class="o">.</span><span class="n">export_onnx_model</span><span class="p">(</span><span class="n">freezed_model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>

<span class="c1"># ========== Export using torch.export ============</span>
<span class="n">example_inputs</span> <span class="o">=</span> <span class="p">(</span><span class="nb">next</span><span class="p">(</span><span class="nb">iter</span><span class="p">(</span><span class="n">val_loader</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),)</span>
<span class="n">model_file_path</span> <span class="o">=</span> <span class="n">os</span><span class="o">.</span><span class="n">path</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">args</span><span class="o">.</span><span class="n">export_dir</span><span class="p">,</span> <span class="n">args</span><span class="o">.</span><span class="n">model_name</span> <span class="o">+</span> <span class="s2">&quot;.pth&quot;</span><span class="p">)</span>
<span class="n">exported_model</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">export</span><span class="p">(</span><span class="n">freezed_model</span><span class="p">,</span> <span class="n">example_inputs</span><span class="p">)</span>
<span class="n">torch</span><span class="o">.</span><span class="n">export</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="n">exported_model</span><span class="p">,</span> <span class="n">model_file_path</span><span class="p">)</span>
</pre></div>
</div>
</section>
<section id="experiment-results">
<h3>Experiment Results<a class="headerlink" href="#experiment-results" title="Link to this heading">#</a></h3>
<section id="image-classification-task-ptq-qat-results">
<h4>1. Image Classification Task PTQ/QAT Results<a class="headerlink" href="#image-classification-task-ptq-qat-results" title="Link to this heading">#</a></h4>
<p>We conduct PTQ and QAT on both ResNet-18 and MobileNet-V2. In these models, all weights, biases, and activations are quantized. All types of tensors are quantized in INT8, per-tensor, symmetric (zero point is 0). The scale factor is in float format. The following table shows the validation accuracy on the ImageNet dataset produced by the above script.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>ResNet-18</p></th>
<th class="head"><p>MobileNetV2</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>Float Model</p></td>
<td><p>69.764 / 89.085</p></td>
<td><p>71.881 / 90.301</p></td>
</tr>
<tr class="row-odd"><td><p>PTQ (INT8)</p></td>
<td><p>69.084 / 88.648</p></td>
<td><p>65.291 / 86.254</p></td>
</tr>
<tr class="row-even"><td><p>QAT (INT8)</p></td>
<td><p>69.469 / 88.872</p></td>
<td><p>68.562 / 88.484</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="object-detection-task-ptq-qat-results">
<h4>2. Object Detection Task PTQ/QAT Results<a class="headerlink" href="#object-detection-task-ptq-qat-results" title="Link to this heading">#</a></h4>
<p>We conduct PTQ and QAT on YOLO-NAS. In this model quantization, we partially quantize the model by assigning the configuration.</p>
<div class="pst-scrollable-table-container"><table class="table">
<thead>
<tr class="row-odd"><th class="head"><p>Metric</p></th>
<th class="head"><p>FP32 model</p></th>
<th class="head"><p>INT8 PTQ</p></th>
<th class="head"><p>INT8 QAT</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><a class="reference external" href="mailto:mAP&#37;&#52;&#48;0&#46;50">mAP<span>&#64;</span>0<span>&#46;</span>50</a></p></td>
<td><p>0.6466</p></td>
<td><p>0.6236</p></td>
<td><p>0.6239</p></td>
</tr>
<tr class="row-odd"><td><p><a class="reference external" href="mailto:mAP&#37;&#52;&#48;0&#46;50">mAP<span>&#64;</span>0<span>&#46;</span>50</a>:0.95</p></td>
<td><p>0.4759</p></td>
<td><p>0.4537</p></td>
<td><p>0.4532</p></td>
</tr>
</tbody>
</table>
</div>
</section>
</section>
</section>
</section>


                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="example_quark_torch_llm_eval_harness_offline.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">LM-Evaluation Harness (Offline)</p>
      </div>
    </a>
    <a class="right-next"
       href="../onnx/onnx_examples.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Accessing ONNX Examples</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <dialog id="pst-secondary-sidebar-modal"></dialog>
                <div id="pst-secondary-sidebar" class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#get-example-code-and-script">Get example code and script</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#ptq">PTQ</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#qat">QAT</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tqt">TQT</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#quick-start">Quick Start</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#fine-grained-user-guide">Fine-Grained User Guide</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#experiment-results">Experiment Results</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#image-classification-task-ptq-qat-results">1. Image Classification Task PTQ/QAT Results</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#object-detection-task-ptq-qat-results">2. Object Detection Task PTQ/QAT Results</a></li>
</ul>
</li>
</ul>
</li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            <p>
      Last updated on Feb 12, 2025.<br/>
  </p>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

<footer class="rocm-footer">
    <div class="container-lg">
        <section class="bottom-menu menu py-45">
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <ul>
                        <li><a href="https://www.amd.com/en/corporate/copyright" target="_blank">Terms and Conditions</a></li>
                        <li><a href="https://quark.docs.amd.com/latest/license.html">Quark Licenses and Disclaimers</a></li>
                        <li><a href="https://www.amd.com/en/corporate/privacy" target="_blank">Privacy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/trademarks" target="_blank">Trademarks</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf" target="_blank">Statement on Forced Labor</a></li>
                        <li><a href="https://www.amd.com/en/corporate/competition" target="_blank">Fair and Open Competition</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf" target="_blank">UK Tax Strategy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/cookies" target="_blank">Cookie Policy</a></li>
                        <!-- OneTrust Cookies Settings button start -->
                        <li><a href="#cookie-settings" id="ot-sdk-btn" class="ot-sdk-show-settings">Cookie Settings</a></li>
                        <!-- OneTrust Cookies Settings button end -->
                    </ul>
                </div>
            </div>
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <div>
                        <span class="copyright">© 2024 Advanced Micro Devices, Inc</span>
                    </div>
                </div>
            </div>
        </section>
    </div>
</footer>

<!-- <div id="rdc-watermark-container">
    <img id="rdc-watermark" src="../_static/images/alpha-watermark.svg" alt="DRAFT watermark"/>
</div> -->
  </body>
</html>