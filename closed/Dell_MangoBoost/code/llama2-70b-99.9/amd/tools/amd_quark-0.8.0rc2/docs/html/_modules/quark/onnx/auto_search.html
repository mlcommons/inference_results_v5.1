
<!DOCTYPE html>


<html lang="en" data-content_root="../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>quark.onnx.auto_search &#8212; Quark 0.8.0rc2 documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  <!--
    this give us a css class that will be invisible only if js is disabled
  -->
  <noscript>
    <style>
      .pst-js-only { display: none !important; }

    </style>
  </noscript>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../_static/styles/theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />
<link href="../../../_static/styles/pydata-sphinx-theme.css?digest=8878045cc6db502f8baf" rel="stylesheet" />

    <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" type="text/css" href="../../../_static/styles/sphinx-book-theme.css?v=a3416100" />
    <link rel="stylesheet" type="text/css" href="../../../_static/graphviz.css?v=4ae1632d" />
    <link rel="stylesheet" type="text/css" href="../../../_static/custom.css?v=6b4ca4e1" />
    <link rel="stylesheet" type="text/css" href="../../../_static/rocm_header.css?v=4044f309" />
    <link rel="stylesheet" type="text/css" href="../../../_static/rocm_footer.css?v=25204c5a" />
    <link rel="stylesheet" type="text/css" href="../../../_static/fonts.css?v=fcff5274" />
  
  <!-- So that users can add custom icons -->
  <script src="../../../_static/scripts/fontawesome.js?digest=8878045cc6db502f8baf"></script>
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf" />
<link rel="preload" as="script" href="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf" />

    <script src="../../../_static/documentation_options.js?v=d42b94c0"></script>
    <script src="../../../_static/doctools.js?v=9bcbadda"></script>
    <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script async="async" src="../../../_static/code_word_breaks.js?v=327952c4"></script>
    <script async="async" src="../../../_static/renameVersionLinks.js?v=929fe5e4"></script>
    <script async="async" src="../../../_static/rdcMisc.js?v=01f88d96"></script>
    <script async="async" src="../../../_static/theme_mode_captions.js?v=15f4ec5d"></script>
    <script src="../../../_static/scripts/sphinx-book-theme.js?v=887ef09a"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/quark/onnx/auto_search';</script>
    <script async="async" src="https://download.amd.com/js/analytics/analyticsinit.js"></script>
    <link rel="icon" href="https://www.amd.com/themes/custom/amd/favicon.ico"/>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" />
<script type="text/javascript">
    window.addEventListener("load", function(event) {
        var coll = document.querySelectorAll('.toggle > .header');  // sdelect the toggles header.
        var i;

        for (i = 0; i < coll.length; i++) {                        
            coll[i].innerText = "Show code ▼\n\n";
            
            coll[i].addEventListener("click", function() {
                var content = this.nextElementSibling;  // code block.
                if (content.style.display === "block") {
                    content.style.display = "none";
                    this.innerText = "Show code ▼\n\n";
                } else {
                    content.style.display = "block";
                    this.innerText = "Hide code ▶";
                }
            });
        }
    });
</script>

  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <div id="pst-skip-link" class="skip-link d-print-none"><a href="#main-content">Skip to main content</a></div>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>Back to top</button>

  
  <dialog id="pst-search-dialog">
    
<form class="bd-search d-flex align-items-center"
      action="../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form>
  </dialog>

  <div class="pst-async-banner-revealer d-none">
  <aside id="bd-header-version-warning" class="d-none d-print-none" aria-label="Version warning"></aside>
</div>

  

<header class="common-header" >
    <nav class="navbar navbar-expand-xl">
        <div class="container-fluid main-nav rocm-header">
            
            <button class="navbar-toggler collapsed" id="nav-icon" data-tracking-information="mainMenuToggle" type="button" data-bs-toggle="collapse" data-bs-target="#navbarSupportedContent" aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
                <span></span>
                <span></span>
                <span></span>
            </button>
            
            <div class="header-logo">
                <a class="navbar-brand" href="https://www.amd.com/">
                    <img src="../../../_static/images/amd-header-logo.svg" alt="AMD Logo" title="AMD Logo" width="90" class="d-inline-block align-text-top hover-opacity"/>
                </a>
                <div class="vr vr mx-40 my-25"></div>
                <a class="klavika-font hover-opacity" href="https://quark.docs.amd.com">Quark</a>
                <a class="header-all-versions" href="https://quark.docs.amd.com/latest/versions.html">Version List</a>
            </div>
            <div class="icon-nav text-center d-flex ms-auto">
            </div>
        </div>
    </nav>
    
    <nav class="navbar navbar-expand-xl second-level-nav">
        <div class="container-fluid main-nav">
            <div class="navbar-nav-container collapse navbar-collapse" id="navbarSupportedContent">
                <ul class="navbar-nav nav-mega me-auto mb-2 mb-lg-0 col-xl-10">
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark" id="navgithub" role="button" aria-expanded="false" target="_blank" >
                                GitHub
                            </a>
                        </li>
                    
                        <li class="nav-item">
                            <a class="nav-link top-level header-menu-links" href="https://gitenterprise.xilinx.com/AMDNeuralOpt/Quark/issues/new/choose" id="navsupport" role="button" aria-expanded="false" target="_blank" >
                                Support
                            </a>
                        </li>
                    
                </ul>
            </div>
        </div>
    </nav>
    
</header>


  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <dialog id="pst-primary-sidebar-modal"></dialog>
      <div id="pst-primary-sidebar" class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  
    
  

<a class="navbar-brand logo" href="../../../index.html">
  
  
  
  
  
  
    <p class="title logo__title">Quark 0.8.0rc2 documentation</p>
  
</a></div>
        <div class="sidebar-primary-item">

<button class="btn search-button-field search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
 <i class="fa-solid fa-magnifying-glass"></i>
 <span class="search-button__default-text">Search</span>
 <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
</button></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Release Notes</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../release_note.html">Release Information</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started with AMD Quark</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../intro.html">Introduction to Quantization</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../install.html">Installation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../basic_usage.html">Basic Usage</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/basic_usage_pytorch.html">AMD Quark for PyTorch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/basic_usage_onnx.html">AMD Quark for ONNX</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/pytorch_examples.html">Accessing PyTorch Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_diffusers.html">Diffusion Model Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_brevitas.html">AMD Quark Extension for Brevitas Integration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_pruning.html">Language Model Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_ptq.html">Language Model PTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_qat.html">Language Model QAT</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval.html">Language Model Evaluation</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_vision.html">Vision Model Quantization using FX Graph Mode</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../onnx/onnx_examples.html">Accessing ONNX Examples</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_BFP.html">Block Floating Point (BFP)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_MX.html">MX Formats</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_adaround.html">Fast Finetune AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_adaquant.html">Fast Finetune AdaQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_cle.html">Cross-Layer Equalization (CLE)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_gptq.html">GPTQ</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_mixed_precision.html">Mixed Precision</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_smoothquant.html">Smooth Quant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_quarot.html">QuaRot</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_dynamic_quantization_llama2.html">Quantizing an Llama-2-7b Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_dynamic_quantization_opt.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_image_classification.html">Quantizing a ResNet50-v1-12 Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_language_models.html">Quantizing an OPT-125M Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_weights_only_quant_int4_matmul_nbits_llama2.html">Quantizing an Llama-2-7b Model Using the ONNX MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_weights_only_quant_int8_qdq_llama2.html">Quantizating Llama-2-7b model using MatMulNBits</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/image_classification_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Image Classification Model</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/object_detection_example_quark_onnx_ryzen_ai_best_practice.html">Best Practice for Quantizing an Object Detection Model</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced AMD Quark Features for PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/user_guide_config_description.html">Configuring PyTorch Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/calibration_methods.html">Calibration Methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/calibration_datasets.html">Calibration Datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/quark_save_load.html">Save and Load Quantized Models</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/export/quark_export.html">Exporting Quantized Models</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/export/quark_export_onnx.html">ONNX Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/export/quark_export_hf.html">HuggingFace Format</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../pytorch/export/quark_export_gguf.html">GGUF Format</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/export/gguf_llamacpp.html">Bridge from Quark to llama.cpp</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/export/quark_export_quark.html">Quark Format</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/export/quark_export_oga.html">ONNX Runtime Gen AI Model Builder</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/quark_torch_best_practices.html">Best Practices for Post-Training Quantization (PTQ)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/debug.html">Debugging quantization Degradation</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/llm_quark.html">Language Model Optimization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_pruning.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_ptq.html">Language Model Post Training Quantization (PTQ) Using Quark</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_qat.html">Language Model QAT Using Quark</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval.html">Language Model Evaluations in Quark</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_perplexity.html">Perplexity Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_rouge_meteor.html">Rouge &amp; Meteor Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_harness.html">LM-Evaluation Harness Evaluations</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../pytorch/example_quark_torch_llm_eval_harness_offline.html">LM-Evaluation Harness (Offline)</a></li>
</ul>
</details></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/tutorial_rotation.html">Quantizing with Rotation and SmoothQuant</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/tutorial_quarot.html">Rotation-based quantization with QuaRot</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/smoothquant.html">Activation/Weight Smoothing (SmoothQuant)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/tutorial_bfp16.html">Block Floating Point 16</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/extensions.html">Extensions</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_pytorch_light.html">Integration with AMD Pytorch-light (APL)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../pytorch/example_quark_torch_brevitas.html">Brevitas Integration</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/adv_mx.html">Using MX (Microscaling)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/adv_two_level.html">Two Level Quantization Formats</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Advanced Quark Features for ONNX</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../onnx/user_guide_config_description.html">Configuring ONNX Quantization</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/appendix_full_quant_config_features.html">Full List of Quantization Config Features</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/config/calibration_methods.html">Calibration methods</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/config/calibration_datasets.html">Calibration datasets</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/config/quantization_strategies.html">Quantization Strategies</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/config/quantization_schemes.html">Quantization Schemes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/config/quantization_symmetry.html">Quantization Symmetry</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/user_guide_supported_optype_datatype.html">Data and OP Types</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/gpu_usage_guide.html">Accelerate with GPUs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/tutorial_mix_precision.html">Mixed Precision</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/bfp16.html">Block Floating Point 16 (BFP16)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/tutorial_bf16_quantization.html">BF16 Quantization</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../onnx/accuracy_improvement_algorithms.html">Accuracy Improvement Algorithms</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/accuracy_algorithms/cle.html">Quantizing Using CrossLayerEqualization (CLE)</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../onnx/accuracy_algorithms/ada.html">Quantization Using AdaQuant and AdaRound</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/accuracy_algorithms/sq.html">SmoothQuant (SQ)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../onnx/example_quark_onnx_gptq.html">Quantizating a model with GPTQ</a></li>
</ul>
</details></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/optional_utilities.html">Optional Utilities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/tools.html">Tools</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">APIs</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../pytorch/pytorch_apis.html">PyTorch APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/pruning/api/index.html">Pruning</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/export/api/index.html">Export</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/pruning/config/index.html">Pruner Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/quantization/config/config/index.html">Quantizer Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/torch/export/config/config/index.html">Exporter Configuration</a></li>
</ul>
</details></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../onnx/onnx_apis.html">ONNX APIs</a><details><summary><span class="toctree-toggle" role="presentation"><i class="fa-solid fa-chevron-down"></i></span></summary><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/quantization/api/index.html">Quantization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/optimize/index.html">Optimization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/calibrate/index.html">Calibration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/onnx_quantizer/index.html">ONNX Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/qdq_quantizer/index.html">QDQ Quantizer</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/quantization/config/config/index.html">Configuration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../autoapi/quark/onnx/quant_utils/index.html">Quantization Utilities</a></li>
</ul>
</details></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Troubleshooting and Support</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../pytorch/pytorch_faq.html">PyTorch FAQ</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../onnx/onnx_faq.html">ONNX FAQ</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
      <div class="sidebar-primary-item">
<div id="ethical-ad-placement"
      class="flat"
      data-ea-publisher="readthedocs"
      data-ea-type="readthedocs-sidebar"
      data-ea-manual="true">
</div></div>
  </div>


      </div>
      
      <main id="main-content" class="bd-main" role="main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article d-print-none">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-angle-right"></span>
  </label></div>
      
        <div class="header-article-item">

<nav aria-label="Breadcrumb" class="d-print-none">
  <ul class="bd-breadcrumbs">
    
    <li class="breadcrumb-item breadcrumb-home">
      <a href="../../../index.html" class="nav-link" aria-label="Home">
        <i class="fa-solid fa-home"></i>
      </a>
    </li>
    
    <li class="breadcrumb-item"><a href="../../index.html" class="nav-link">Module code</a></li>
    
    <li class="breadcrumb-item active" aria-current="page"><span class="ellipsis">quark.onnx.auto_search</span></li>
  </ul>
</nav>
</div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<button class="btn btn-sm nav-link pst-navbar-icon theme-switch-button pst-js-only" aria-label="Color mode" data-bs-title="Color mode"  data-bs-placement="bottom" data-bs-toggle="tooltip">
  <i class="theme-switch fa-solid fa-sun                fa-lg" data-mode="light" title="Light"></i>
  <i class="theme-switch fa-solid fa-moon               fa-lg" data-mode="dark"  title="Dark"></i>
  <i class="theme-switch fa-solid fa-circle-half-stroke fa-lg" data-mode="auto"  title="System Settings"></i>
</button>


<button class="btn btn-sm pst-navbar-icon search-button search-button__button pst-js-only" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
</button>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for quark.onnx.auto_search</h1><div class="highlight"><pre>
<span></span>#
# Modifications copyright(c) 2024 Advanced Micro Devices,Inc. All rights reserved.
# SPDX-License-Identifier: MIT
#
# -------------------------------------------------------------------------
# Copyright (c) Microsoft Corporation. All rights reserved.
# Licensed under the MIT License. See License.txt in the project root for
# license information.
# --------------------------------------------------------------------------
import shutil
import copy
import os
import random
import time
import logging
import onnxruntime as ort
import numpy as np
from typing import Union, Optional, Any, Dict, Tuple

from onnxruntime.quantization.calibrate import CalibrationDataReader
from onnxruntime.quantization.calibrate import CalibrationMethod
from onnxruntime.quantization.quant_utils import QuantType
from quark.onnx.quantization.config.config import Config
from quark.onnx.quantization.api import ModelQuantizer
from quark.onnx.quant_utils import PowerOfTwoMethod
from quark.onnx.operators.custom_ops import get_library_path

Level1_config_keys = [
    &#39;calibrate_method&#39;,
    &#39;quant_format&#39;,
    &#39;activation_type&#39;,
    &#39;weight_type&#39;,
    &#39;input_nodes&#39;,
    &#39;output_nodes&#39;,
    &#39;op_types_to_quantize&#39;,
    &#39;nodes_to_quantize&#39;,
    &#39;nodes_to_exclude&#39;,
    &#39;specific_tensor_precision&#39;,
    &#39;execution_providers&#39;,
    &#39;per_channel&#39;,
    &#39;reduce_range&#39;,
    &#39;optimize_model&#39;,
    &#39;use_dynamic_quant&#39;,
    &#39;use_external_data_format&#39;,
    &#39;convert_fp16_to_fp32&#39;,
    &#39;convert_nchw_to_nhwc&#39;,
    &#39;include_sq&#39;,
    &#39;include_cle&#39;,
    &#39;include_auto_mp&#39;,
    &#39;include_fast_ft&#39;,
    &#39;enable_npu_cnn&#39;,
    &#39;enable_npu_transformer&#39;,
    &#39;debug_mode&#39;,
    &#39;print_summary&#39;,
    &#39;ignore_warnings&#39;,
    &#39;log_severity_level&#39;,
    &#39;extra_options&#39;,
]
Level2_config_keys = [
    &#39;ActivationSymmetric&#39;,
    &#39;WeightSymmetric&#39;,
    &#39;UseUnsignedReLU&#39;,
    &#39;QuantizeBias&#39;,
    &#39;Int32Bias&#39;,
    &#39;RemoveInputInit&#39;,
    &#39;SimplifyModel&#39;,
    &#39;EnableSubgraph&#39;,
    &#39;ForceQuantizeNoInputCheck&#39;,
    &#39;MatMulConstBOnly&#39;,
    &#39;AddQDQPairToWeight&#39;,
    &#39;OpTypesToExcludeOutputQuantization&#39;,
    &#39;DedicatedQDQPair&#39;,
    &#39;QDQOpTypePerChannelSupportToAxis&#39;,
    &#39;UseQDQVitisCustomOps&#39;,
    &#39;CalibTensorRangeSymmetric&#39;,
    &#39;CalibMovingAverage&#39;,
    &#39;CalibMovingAverageConstant&#39;,
    &#39;Percentile&#39;,
    &#39;RandomDataReaderInputDataRange&#39;,
    &#39;Int16Scale&#39;,
    &#39;MinMSEMode&#39;,
    &#39;ConvertBNToConv&#39;,
    &#39;ConvertReduceMeanToGlobalAvgPool&#39;,
    &#39;SplitLargeKernelPool&#39;,
    &#39;ConvertSplitToSlice&#39;,
    &#39;FuseInstanceNorm&#39;,
    &#39;FuseL2Norm&#39;,
    &#39;FuseLayerNorm&#39;,
    &#39;ConvertClipToRelu&#39;,
    &#39;SimulateDPU&#39;,
    &#39;ConvertLeakyReluToDPUVersion&#39;,
    &#39;ConvertSigmoidToHardSigmoid&#39;,
    &#39;ConvertHardSigmoidToDPUVersion&#39;,
    &#39;ConvertAvgPoolToDPUVersion&#39;,
    &#39;ConvertReduceMeanToDPUVersion&#39;,
    &#39;ConvertSoftmaxToDPUVersion&#39;,
    &#39;NPULimitationCheck&#39;,
    &#39;AdjustShiftCut&#39;,
    &#39;AdjustShiftBias&#39;,
    &#39;AdjustShiftRead&#39;,
    &#39;AdjustShiftWrite&#39;,
    &#39;AdjustHardSigmoid&#39;,
    &#39;AdjustShiftSwish&#39;,
    &#39;AlignConcat&#39;,
    &#39;AlignPool&#39;,
    &#39;AlignPad&#39;,
    &#39;AlignSlice&#39;,
    &#39;AlignEltwiseQuantType&#39;,
    &#39;ReplaceClip6Relu&#39;,
    &#39;CLESteps&#39;,
    &#39;CLETotalLayerDiffThreshold&#39;,
    &#39;CLEScaleAppendBias&#39;,
    &#39;FastFinetune&#39;,
    &#39;SmoothAlpha&#39;,
    &#39;RemoveQDQConvRelu&#39;,
    &#39;RemoveQDQConvLeakyRelu&#39;,
    &#39;RemoveQDQConvPRelu&#39;,
    &#39;RemoveQDQInstanceNorm&#39;,
    &#39;FoldBatchNorm&#39;,
    &#39;FixShapes&#39;,
    &#39;MixedPrecisionTensor&#39;,
    &#39;AutoMixprecision&#39;,
    &#39;FoldRelu&#39;,
    &#39;CalibDataSize&#39;,
    &#39;SaveTensorHistFig&#39;,
    &#39;WeightsOnly&#39;,
    &#39;BFPAttributes&#39;,
]
Level3_config_keys = [
    &#39;DataSize&#39;, &#39;FixedSeed&#39;, &#39;BatchSize&#39;, &#39;NumIterations&#39;, &#39;LearningRate&#39;, &#39;OptimAlgorithm&#39;, &#39;OptimDevice&#39;, &#39;EarlyStop&#39;,
    &#39;FixedSeed&#39;, &#39;NumBatches&#39;, &#39;LRAdjust&#39;, &#39;TargetOpType&#39;, &#39;SelectiveUpdate&#39;, &#39;UpdataBias&#39;, &#39;OutputQDQ&#39;, &#39;DropRatio&#39;,
    &#39;LogPeriod&#39;
]


<div class="viewcode-block" id="l2_metric">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.l2_metric">[docs]</a>
def l2_metric(base_input: Any, ref_input: Any) -&gt; Any:
    &quot;&quot;&quot;
    Calculate the L2 metric between baseline and reference inputs.

    Args:
        base_input: Baseline input as a numpy array of float32.
        ref_input: Reference input as a numpy array of float32.

    Returns:
        The L2 metric as a float32 value.

    Note:
        Only np.ndarray datatype is accepted as input.
    &quot;&quot;&quot;
    return np.mean(np.square(base_input - ref_input)).astype(float)</div>



<div class="viewcode-block" id="l1_metric">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.l1_metric">[docs]</a>
def l1_metric(base_input: Any, ref_input: Any) -&gt; Any:
    &quot;&quot;&quot;
    Calculate the L1 metric between baseline and reference inputs.

    Args:
        base_input: Baseline input as a numpy array of float32.
        ref_input: Reference input as a numpy array of float32.

    Returns:
        The L1 metric as a float32 value.

    Note:
        Only np.ndarray datatype is accepted as input.
    &quot;&quot;&quot;
    return np.mean(np.abs(base_input - ref_input)).astype(float)</div>



<div class="viewcode-block" id="cos_metric">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.cos_metric">[docs]</a>
def cos_metric(base_input: Any, ref_input: Any) -&gt; Any:
    &quot;&quot;&quot;
    Calculate the cosine metric between baseline and reference inputs.

    Args:
        base_input: Baseline input as a numpy array of float32.
        ref_input: Reference input as a numpy array of float32.

    Returns:
        The cosine metric as a float32 value. Value range: [0.0, 1.0]

    Note:
        Only np.ndarray datatype is accepted as input.
    &quot;&quot;&quot;
    v1 = base_input.reshape(-1)
    v2 = ref_input.reshape(-1)
    num = np.dot(v1, v2)
    denom = np.linalg.norm(v1) * np.linalg.norm(v2)
    return 0.5 + 0.5 * (num / denom) if denom != 0 else 0</div>



<div class="viewcode-block" id="psnr_metric">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.psnr_metric">[docs]</a>
def psnr_metric(base_input: Any, ref_input: Any) -&gt; Any:
    &quot;&quot;&quot;
    Calculate the psnr metric between baseline and reference inputs.

    Args:
        base_input: Baseline input as a numpy array of float32.
        ref_input: Reference input as a numpy array of float32.

    Returns:
        The psnr metric as a float32 value.

    Note:
        Only np.ndarray datatype is accepted as input.
    &quot;&quot;&quot;
    mse_value = np.mean((base_input / 1.0 - ref_input / 1.0)**2)
    if mse_value &lt; 1e-10:
        return 100
    psnr_value = 20 * np.log10(255 / np.sqrt(mse_value))
    return psnr_value</div>



<div class="viewcode-block" id="ssim_metric">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.ssim_metric">[docs]</a>
def ssim_metric(base_input: Any, ref_input: Any) -&gt; Any:
    &quot;&quot;&quot;
    Calculate the ssim metric between baseline and reference inputs.

    Args:
        base_input: Baseline input as a numpy array of float32.
        ref_input: Reference input as a numpy array of float32.

    Returns:
        The ssim metric as a float32 value.

    Note:
        Only np.ndarray datatype is accepted as input.
    &quot;&quot;&quot;
    y_true = ref_input
    y_pred = base_input
    u_true = np.mean(y_true)
    u_pred = np.mean(y_pred)
    var_ture = np.var(y_true)
    var_pred = np.var(y_pred)
    std_true = np.sqrt(var_ture)
    std_pred = np.sqrt(var_pred)
    R = 255
    c1 = np.square(0.01 * R)
    c2 = np.square(0.03 * R)
    ssim = (2 * u_true * u_pred + c1) * (2 * std_pred * std_true + c2)
    denom = (u_true**2 + u_pred**2 + c1) * (var_pred + var_ture + c2)
    return ssim / denom</div>



def split_config_levels(input_config: Dict[str, Any]) -&gt; Tuple[Dict[str, Any], Dict[str, Any], Dict[str, Any]]:
    raw_config = copy.deepcopy(input_config)
    temp_level1_space_config: Dict[str, Any] = {}
    temp_level2_space_config: Dict[str, Any] = {}
    temp_level3_space_config: Dict[str, Any] = {}
    #  search space split into 3 levels
    if &#39;extra_options&#39; in raw_config.keys():
        if &#39;FastFinetune&#39; in raw_config[&#39;extra_options&#39;].keys():
            temp_level3_space_config = copy.deepcopy(raw_config[&#39;extra_options&#39;][&#39;FastFinetune&#39;])
            del raw_config[&#39;extra_options&#39;][&#39;FastFinetune&#39;]
            if len(raw_config[&#39;extra_options&#39;]) &gt; 0:
                temp_level2_space_config = copy.deepcopy(raw_config[&#39;extra_options&#39;])
            del raw_config[&#39;extra_options&#39;]
            temp_level1_space_config = copy.deepcopy(raw_config)
        else:
            # judge is the dict is empty
            if len(raw_config[&#39;extra_options&#39;]) &gt; 0:
                temp_level2_space_config = copy.deepcopy(raw_config[&#39;extra_options&#39;])
                del raw_config[&#39;extra_options&#39;]
            temp_level1_space_config = copy.deepcopy(raw_config)
    else:
        temp_level1_space_config = copy.deepcopy(raw_config)
    return temp_level1_space_config, temp_level2_space_config, temp_level3_space_config


<div class="viewcode-block" id="buildin_eval_func">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.buildin_eval_func">[docs]</a>
def buildin_eval_func(onnx_path: str, data_reader: Any, save_path: str = &#39;&#39;, save_prefix: str = &quot;iter_x_&quot;) -&gt; str:
    &quot;&quot;&quot;
    Buildin evalation function using data_reader

    Args:
        onnx_path: onnx model path that will excute evalution, it can be  either float porint or quantized onnx model
        data_reader: user defined data_reader
        save_path: path used to save the output result
        save_prefix: prefix string used to name the saved output

    Note: Data reader here should be defined as dataloader.Because the raw data reader is iterator, it&#39;s
           not convient for evaluation.
    &quot;&quot;&quot;
    # TODO check the onnx
    if &#39;ROCMExecutionProvider&#39; in ort.get_available_providers():
        device = &#39;ROCM&#39;
        providers = [&#39;ROCMExecutionProvider&#39;]
    elif &#39;CUDAExecutionProvider&#39; in ort.get_available_providers():
        device = &#39;CUDA&#39;
        providers = [&#39;CUDAExecutionProvider&#39;]
    else:
        device = &#39;CPU&#39;
        providers = [&#39;CPUExecutionProvider&#39;]
    so = ort.SessionOptions()
    so.register_custom_ops_library(get_library_path(device))
    ort_session = ort.InferenceSession(onnx_path, so, providers=providers)

    for excute_idx, data in enumerate(data_reader):
        output = ort_session.run(None, data)
        excute_idx += 1
        if save_path is not None:
            temp_save_path = os.path.join(save_path, str(save_prefix) + str(excute_idx) + &quot;.npy&quot;)
            output = np.concatenate([item.reshape(-1) for item in output])
            np.save(temp_save_path, output)
    return save_path</div>



def logger_config(log_path: str = &#39;./auto_search.log&#39;, logging_name: str = &#39;auto search&#39;) -&gt; logging.Logger:
    logger = logging.getLogger(logging_name)

    logger.setLevel(level=logging.INFO)

    handler = logging.FileHandler(log_path, encoding=&#39;UTF-8&#39;)
    handler.setLevel(logging.INFO)

    console = logging.StreamHandler()
    console.setLevel(logging.DEBUG)

    logger.addHandler(handler)
    logger.addHandler(console)
    return logger


METRICS = {
    &quot;L2&quot;: l2_metric,
    &quot;L1&quot;: l1_metric,
    &quot;cos&quot;: cos_metric,
    &quot;psnr&quot;: psnr_metric,
    &quot;ssim&quot;: ssim_metric,
}


class AutoSearchConfig:
    search_space: Dict[str, Any] = {
        &quot;calibrate_method&quot;: [
            PowerOfTwoMethod.MinMSE, PowerOfTwoMethod.NonOverflow, CalibrationMethod.MinMax, CalibrationMethod.Entropy,
            CalibrationMethod.Percentile
        ],
        &quot;activation_type&quot;: [QuantType.QInt8, QuantType.QInt16],
        &quot;weight_type&quot;: [QuantType.QInt8, QuantType.QInt16],
        &quot;include_cle&quot;: [True, False],
        &quot;include_auto_mp&quot;: [False, True],
        &quot;include_fast_ft&quot;: [False, True],
        &quot;include_sq&quot;: [False, True],
        &quot;extra_options&quot;: {
            &quot;ActivationSymmetric&quot;: [True, False],
            &quot;WeightSymmetric&quot;: [True, False],
            &quot;CalibMovingAverage&quot;: [True, False],
            &quot;CalibMovingAverageConstant&quot;: [0.01, 0.001],
            &quot;Percentile&quot;: [99.99, 99.999],
            &quot;SmoothAlpha&quot;: [0.5, 0.6],
            &#39;FastFinetune&#39;: {
                &#39;DataSize&#39;: [500, 1000],
                &#39;NumIterations&#39;: [100, 1000],
                &#39;OptimAlgorithm&#39;: [&#39;adaround&#39;, &#39;adaquant&#39;],
                &#39;LearningRate&#39;: [0.01, 0.001, 0.0001],
            }
        }
    }
    search_metric: str = &quot;L2&quot;
    search_algo: str = &quot;grid_search&quot;  # candidates: &quot;grid_search&quot;, &quot;random&quot;
    search_evaluator = None
    search_metric_tolerance: float = 2.00
    search_cache_dir: str = &quot;./&quot;
    search_output_dir: str = &quot;./&quot;
    search_log_path: str = &quot;./auto_search.log&quot;

    search_stop_condition: dict[str, Any] = {
        &quot;find_n_candidates&quot;: -1,
        &quot;find_best_candidate&quot;: -1,
        &quot;iteration_limit&quot;: 10000,
        &quot;time_limit&quot;: 36000,  # unit: second
    }


<div class="viewcode-block" id="AssembleIdxs">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.AssembleIdxs">[docs]</a>
class AssembleIdxs():
    &quot;&quot;&quot;
    List all the combination of one list.
    Example:
            input_idxs: [[1,2,], [3,4]]
            output: [[1,3], [1,4], [2,3], [2,4]]

    Args:
        values_idxs

    Note:
        Only list the item in the input[i] list.
    &quot;&quot;&quot;

    def __init__(self, values_idxs: Any) -&gt; None:
        &quot;&quot;&quot;
        Initilize the input idxs for listing combination.

    Args:
        values_idxs: input list.
    &quot;&quot;&quot;
        self.values_idxs = values_idxs
        self.values_length: int = len(values_idxs)
        self.result: list[Union[int, list[int]]] = []

<div class="viewcode-block" id="AssembleIdxs.search_forward">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.AssembleIdxs.search_forward">[docs]</a>
    def search_forward(self, item_forward: list[Any]) -&gt; None:
        &quot;&quot;&quot;
        Recresively find the next item until the last one.

        Args:
            item_forward: searched item collection.
        &quot;&quot;&quot;
        item_forward_length = len(item_forward)
        if item_forward_length == self.values_length:
            self.result.append(copy.deepcopy(item_forward))
        else:
            for item in self.values_idxs[item_forward_length]:
                item_forward.append(item)
                self.search_forward(item_forward)
                item_forward.pop()</div>


<div class="viewcode-block" id="AssembleIdxs.run">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.AssembleIdxs.run">[docs]</a>
    def run(self, ) -&gt; list[Union[int, list[int]]]:
        &quot;&quot;&quot;
         Excute the assemble process and return the result
        &quot;&quot;&quot;
        self.search_forward([])
        return self.result</div>
</div>



<div class="viewcode-block" id="SearchSpace">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.SearchSpace">[docs]</a>
class SearchSpace():
    &quot;&quot;&quot;
    Build the all possible search space from the input.
    # TODO remove the invalid config generated by the search space
    # TODO give the config priority
    # TODO validate the space dict right

    Args:
        config: config which includes the search space defined by the list

    Note:
        Because the search space is in difference levels, so we need to split the level of the search space.
    &quot;&quot;&quot;

    def __init__(self, conf: Dict[str, Any]) -&gt; None:
        self.raw_search_space: dict[str, Any] = conf

        self.all_configs: list[dict[str, str]] = []
        self.all_spaces: list[Any] = []

        self.level1_space: list[Any] = []
        self.level2_space: list[Any] = []
        self.level3_space: list[Any] = []
        self.level1_space_config: Dict[str, Any] = {}
        self.level2_space_config: Dict[str, Any] = {}
        self.level3_space_config: Dict[str, Any] = {}

        #  search space split into 3 levels
        self.level1_space_config, self.level2_space_config, self.level3_space_config = split_config_levels(
            self.raw_search_space)

        # validate the config
        if len(self.level1_space_config) &gt; 0:
            for level1_key in self.level1_space_config.keys():
                if level1_key not in Level1_config_keys:
                    print(
                        f&quot;{level1_key} is not supported yet or your input config is wrong! Please check it! And this setting will be ignored!&quot;
                    )
        if len(self.level2_space_config) &gt; 0:
            for level2_key in self.level2_space_config.keys():
                if level2_key not in Level2_config_keys:
                    print(
                        f&quot;{level2_key} is not supported yet or your input config is wrong! Please check it! And this setting will be ignored!&quot;
                    )
        if len(self.level3_space_config) &gt; 0:
            for level3_key in self.level3_space_config.keys():
                if level3_key not in Level3_config_keys:
                    print(
                        f&quot;{level3_key} is not supported yet or your input config is wrong! Please check it! And this setting will be ignored!&quot;
                    )

    def build_search_space(self, space_dict: Dict[str, Any]) -&gt; list[Union[int, list[int]]]:
        values = space_dict.values()
        values_lengths = [[i for i in range(len(item))] for item in values]
        assemble_idxs_ins = AssembleIdxs(values_lengths)
        space_result = assemble_idxs_ins.run()
        del assemble_idxs_ins
        return space_result

<div class="viewcode-block" id="SearchSpace.three_level_spaces">
<a class="viewcode-back" href="../../../autoapi/quark/onnx/auto_search/index.html#quark.onnx.auto_search.SearchSpace.three_level_spaces">[docs]</a>
    def three_level_spaces(self, ) -&gt; list[Any]:
        &quot;&quot;&quot;
        According to the user defined search space, list all the possible configs.
        There several situation we need to tell it apart(splited spaces):
        leve11 + level2
        level1 + level3
        level1 + level3
        level1
        &quot;&quot;&quot;

        # level1 + level2
        if (self.level1_space_config != {}) and (self.level2_space_config != {}) and \
                (self.level3_space_config == {}):
            self.level1_space = self.build_search_space(self.level1_space_config)
            self.level2_space = self.build_search_space(self.level2_space_config)
            simple_joint_space = [self.level1_space, self.level2_space]
            assemble_idxs_ins = AssembleIdxs(simple_joint_space)
            space_result = assemble_idxs_ins.run()
            del assemble_idxs_ins
            self.all_spaces = copy.deepcopy(space_result)
        # level1 + level3
        elif (self.level1_space_config != {}) and (self.level2_space_config == {}) and \
                (self.level3_space_config != {}):
            self.level1_space = self.build_search_space(self.level1_space_config)
            self.level3_space = self.build_search_space(self.level3_space_config)
            simple_joint_space = [self.level1_space, self.level3_space]
            assemble_idxs_ins = AssembleIdxs(simple_joint_space)
            space_result = assemble_idxs_ins.run()
            del assemble_idxs_ins
            self.all_spaces = copy.deepcopy(space_result)
        # level1 + level2 + level3
        elif (self.level1_space_config != {}) and (self.level2_space_config != {}) and \
                (self.level3_space_config != {}):
            self.level1_space = self.build_search_space(self.level1_space_config)
            self.level2_space = self.build_search_space(self.level2_space_config)
            self.level3_space = self.build_search_space(self.level3_space_config)
            simple_joint_space = [self.level1_space, self.level2_space, self.level3_space]
            assemble_idxs_ins = AssembleIdxs(simple_joint_space)
            space_result = assemble_idxs_ins.run()
            del assemble_idxs_ins
            self.all_spaces = copy.deepcopy(space_result)
        # level1
        elif (self.level1_space_config != {}) and (self.level2_space_config == {}) and \
                (self.level3_space_config == {}):
            self.level1_space = self.build_search_space(self.level1_space_config)
            self.all_spaces = self.level1_space

        return self.all_spaces</div>


    def get_all_configs(self, ) -&gt; list[Any]:
        # make all space to into configs
        self.three_level_spaces()
        # level1 + level2 serch space
        if (self.level1_space_config != {}) and (self.level2_space_config != {}) and \
                (self.level3_space_config == {}):

            level1_keys = list(self.level1_space_config.keys())
            level2_keys = list(self.level2_space_config.keys())
            for one_space in self.all_spaces:
                temp_level1_space = one_space[0]
                temp_level2_space = one_space[1]
                temp_level1_vals = [
                    self.level1_space_config[level1_keys[level1_idx]][temp_level1_space[level1_idx]]
                    for level1_idx in range(len(temp_level1_space))
                ]
                temp_level1_config = {key_item: val_item for key_item, val_item in zip(level1_keys, temp_level1_vals)}
                temp_level2_vals = [
                    self.level2_space_config[level2_keys[level2_idx]][temp_level2_space[level2_idx]]
                    for level2_idx in range(len(temp_level2_space))
                ]
                temp_level2_config = {key_item: val_item for key_item, val_item in zip(level2_keys, temp_level2_vals)}

                temp_level1_config[&#39;extra_options&#39;] = temp_level2_config
                self.all_configs.append(copy.deepcopy(temp_level1_config))
        # level1 + level3 search space
        elif (self.level1_space_config != {}) and (self.level2_space_config == {}) and \
                (self.level3_space_config != {}):
            level1_keys = list(self.level1_space_config.keys())
            level3_keys = list(self.level3_space_config.keys())
            for one_space in self.all_spaces:
                temp_level1_space = one_space[0]
                temp_level3_space = one_space[1]
                temp_level1_vals = [
                    self.level1_space_config[level1_keys[level1_idx]][temp_level1_space[level1_idx]]
                    for level1_idx in range(len(temp_level1_space))
                ]
                temp_level1_config = {key_item: val_item for key_item, val_item in zip(level1_keys, temp_level1_vals)}
                temp_level3_vals = [
                    self.level3_space_config[level3_keys[level3_idx]][temp_level3_space[level3_idx]]
                    for level3_idx in range(len(temp_level3_space))
                ]
                temp_level3_config = {key_item: val_item for key_item, val_item in zip(level3_keys, temp_level3_vals)}

                temp_level1_config[&#39;extra_options&#39;] = {&quot;FastFinetune&quot;: temp_level3_config}
                self.all_configs.append(copy.deepcopy(temp_level1_config))
        # level1 + level2 + level3 search space
        elif (self.level1_space_config != {}) and (self.level2_space_config != {}) and \
                (self.level2_space_config != {}):
            level1_keys = list(self.level1_space_config.keys())
            level2_keys = list(self.level2_space_config.keys())
            level3_keys = list(self.level3_space_config.keys())
            for one_space in self.all_spaces:
                temp_level1_space = one_space[0]
                temp_level2_space = one_space[1]
                temp_level3_space = one_space[2]
                temp_level1_vals = [
                    self.level1_space_config[level1_keys[level1_idx]][temp_level1_space[level1_idx]]
                    for level1_idx in range(len(temp_level1_space))
                ]
                temp_level1_config = {key_item: val_item for key_item, val_item in zip(level1_keys, temp_level1_vals)}

                temp_level2_vals = [
                    self.level2_space_config[level2_keys[level2_idx]][temp_level2_space[level2_idx]]
                    for level2_idx in range(len(temp_level2_space))
                ]
                temp_level2_config = {key_item: val_item for key_item, val_item in zip(level2_keys, temp_level2_vals)}

                temp_level3_vals = [
                    self.level3_space_config[level3_keys[level3_idx]][temp_level3_space[level3_idx]]
                    for level3_idx in range(len(temp_level3_space))
                ]
                temp_level3_config = {key_item: val_item for key_item, val_item in zip(level3_keys, temp_level3_vals)}

                temp_level2_config[&#39;FastFinetune&#39;] = temp_level3_config
                temp_level1_config[&#39;extra_options&#39;] = temp_level2_config
                self.all_configs.append(copy.deepcopy(temp_level1_config))
        # level1 search space
        elif (self.level1_space_config != {}) and (self.level2_space_config == {}) and \
                (self.level2_space_config == {}):
            level1_keys = list(self.level1_space_config.keys())

            for one_space in self.all_spaces:
                temp_level1_space = one_space
                temp_level1_vals = [
                    self.level1_space_config[level1_keys[level1_idx]][temp_level1_space[level1_idx]]
                    for level1_idx in range(len(temp_level1_space))
                ]
                temp_level1_config = {key_item: val_item for key_item, val_item in zip(level1_keys, temp_level1_vals)}

                # print(temp_level1_config)
                self.all_configs.append(copy.deepcopy(temp_level1_config))
        else:
            print(&quot;wrong config setting!&quot;)

        return self.all_configs

    def verify_one_config_base(self, verify_item: str, base_item: str, base_config: Dict[str, Any],
                               verify_standard: Any) -&gt; bool:
        valid_flag = True
        if base_item not in base_config.keys():
            valid_flag = False
            print(f&quot;Please set {base_item} to be {verify_standard}, when you use {verify_item}! &quot;)
        elif base_item in base_config.keys() and base_config[base_item] != verify_standard:
            valid_flag = False
            print(f&quot;Please set {base_item} to be {verify_standard}, when you use {verify_item}! &quot;)
        return valid_flag

    def verify_one_config(self, verify_item: str, verify_config: Dict[str, Any], base_item: str,
                          base_config: Dict[str, Any], verify_standard: Any) -&gt; Dict[str, Any]:
        if verify_item in verify_config.keys():
            if base_item not in base_config.keys():
                print(f&quot;Please set {base_item} to be {verify_standard}, when you use {verify_item}! &quot;)
                del verify_config[verify_item]
            elif base_item in base_config.keys() and base_config[base_item] != verify_standard:
                print(f&quot;Please set {base_item} to be {verify_standard}, when you use {verify_item}! &quot;)
                del verify_config[verify_item]
        return verify_config

    def remove_invalid_configs(self, input_all_coinfgs: list[Dict[str, Any]]) -&gt; list[Any]:
        valid_configs = []
        for _, item_config in enumerate(input_all_coinfgs):
            item_config_l1, item_config_l2, item_config_l3 = split_config_levels(item_config)
            # level1 pass
            # level1 + level2
            if len(item_config_l1) &gt; 0 and len(item_config_l2) &gt; 0 and len(item_config_l3) == 0:
                # verify &quot;CalibMovingAverage&quot; and &quot;CalibMovingAverageConstant&quot;
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverage&quot;, item_config_l2, &quot;calibrate_method&quot;,
                                                        item_config_l1, CalibrationMethod.MinMax)
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverageConstant&quot;, item_config_l2,
                                                        &quot;calibrate_method&quot;, item_config_l1, CalibrationMethod.MinMax)
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverageConstant&quot;, item_config_l2,
                                                        &quot;CalibMovingAverageConstant&quot;, item_config_l2, True)
                # verify &quot;Percentile&quot;
                item_config_l2 = self.verify_one_config(&#39;Percentile&#39;, item_config_l2, &#39;calibrate_method&#39;,
                                                        item_config_l1, CalibrationMethod.Percentile)
                # verify &quot;SmoothAlpha&quot;
                item_config_l2 = self.verify_one_config(&quot;SmoothAlpha&quot;, item_config_l2, &quot;include_sq&quot;, item_config_l1,
                                                        True)
                item_config_l1[&#39;extra_options&#39;] = item_config_l2
            # level1 + level3
            elif len(item_config_l1) &gt; 0 and len(item_config_l2) == 0 and len(item_config_l3) &gt; 0:
                # verify FastFinetune
                item_config_l3_flag = self.verify_one_config_base(&quot;FastFinetune&quot;, &quot;include_fast_ft&quot;, item_config_l1,
                                                                  True)
                if item_config_l3_flag:
                    item_config_l1[&#39;extra_options&#39;] = {&#39;FastFinetune&#39;: item_config_l3}
            # level1 + level2 + level3
            elif len(item_config_l1) &gt; 0 and len(item_config_l2) &gt; 0 and len(item_config_l3) &gt; 0:
                # verify &quot;CalibMovingAverage&quot; and &quot;CalibMovingAverageConstant&quot;
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverage&quot;, item_config_l2, &quot;calibrate_method&quot;,
                                                        item_config_l1, CalibrationMethod.MinMax)
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverageConstant&quot;, item_config_l2,
                                                        &quot;calibrate_method&quot;, item_config_l1, CalibrationMethod.MinMax)
                item_config_l2 = self.verify_one_config(&quot;CalibMovingAverageConstant&quot;, item_config_l2,
                                                        &quot;CalibMovingAverageConstant&quot;, item_config_l2, True)
                # verify &quot;Percentile&quot;
                item_config_l2 = self.verify_one_config(&#39;Percentile&#39;, item_config_l2, &#39;calibrate_method&#39;,
                                                        item_config_l1, CalibrationMethod.Percentile)
                # verify &quot;SmoothAlpha&quot;
                item_config_l2 = self.verify_one_config(&quot;SmoothAlpha&quot;, item_config_l2, &quot;include_sq&quot;, item_config_l1,
                                                        True)
                # verify FastFinetune
                item_config_l3_flag = self.verify_one_config_base(&quot;FastFinetune&quot;, &quot;include_fast_ft&quot;, item_config_l1,
                                                                  True)

                if len(item_config_l2) &gt; 0:
                    item_config_l1[&#39;extra_options&#39;] = item_config_l2
                if len(item_config_l2) &gt; 0 and item_config_l3_flag:
                    item_config_l1[&#39;extra_options&#39;][&#39;FastFinetune&#39;] = item_config_l3
                elif len(item_config_l2) == 0 and item_config_l3_flag:
                    item_config_l1[&#39;extra_options&#39;] = {&#39;FastFinetune&#39;: item_config_l3}

            if item_config_l1 not in valid_configs:
                valid_configs.append(item_config_l1)

        print(f&quot;The invalid configs ratio is {len(self.all_configs) - len(valid_configs)} / {len(self.all_configs)}&quot;)

        return valid_configs</div>



class AutoSearch():

    def __init__(self,
                 config: Config,
                 auto_search_config: AutoSearchConfig,
                 model_input: str,
                 model_output: str,
                 eval_dataloader: Any = None,
                 calibration_data_reader: Union[CalibrationDataReader, None, Any] = None,
                 calibration_data_path: Optional[str] = None) -&gt; None:
        # basic settings
        self.config = config
        self.config_backup = copy.deepcopy(config)
        self.auto_search_config = auto_search_config
        self.model_input = model_input
        self.model_output = model_output
        self.calibration_data_reader = calibration_data_reader
        self.calibration_data_path = calibration_data_path
        self.eval_dataloader = eval_dataloader if eval_dataloader is not None else calibration_data_reader
        self.searched_space: Dict[int, float] = {}

        self.cache_dir = self.auto_search_config.search_cache_dir
        self.output_dir = self.auto_search_config.search_output_dir
        if not os.path.exists(self.cache_dir):
            os.makedirs(self.cache_dir)
        if not os.path.exists(self.output_dir):
            os.makedirs(self.output_dir)

        self.logger = logger_config(os.path.join(self.auto_search_config.search_output_dir, &quot;auto_search.log&quot;),
                                    logging_name=&quot;auto_search log&quot;)

        if self.auto_search_config.search_evaluator is None:
            metric_str = self.auto_search_config.search_metric
            if metric_str in METRICS.keys():
                self.metric = METRICS[self.auto_search_config.search_metric]
            else:
                self.metric = METRICS[&quot;L2&quot;]
                self.logger.error(
                    f&quot;search metric:{metric_str} is not supported yet! you can change your metric setting or set it in user defined evaluator!&quot;
                )

        self.evaluator = self.build_evaluator()
        self.quantizer = self.build_quantize_instance()
        self.all_configs = self.build_all_configs(search_space_config=self.auto_search_config.search_space)

        # search stop conditions initilization
        self.iterations = 0
        self.time_consumed = 0.0
        self.candidates: list[Dict[str, Any]] = []
        self.best_candidate = None

    def build_evaluator(self, ) -&gt; Any:
        if self.auto_search_config.search_evaluator is not None:
            return self.auto_search_config.search_evaluator
        else:
            # using self.calibration_data_reader to inference float and quantized model, and cal the L2 distance
            return buildin_eval_func

    def build_quantize_instance(self, ) -&gt; ModelQuantizer:
        return ModelQuantizer(self.config)

    def build_all_configs(self, search_space_config: Dict[str, Any]) -&gt; list[Any]:
        search_space = SearchSpace(search_space_config)
        all_configs = search_space.get_all_configs()
        del search_space
        return all_configs

    def sampler(self, input_idxs: list[Dict[str, Any]]) -&gt; list[Dict[str, Any]]:
        if self.auto_search_config.search_algo == &quot;grid_search&quot;:
            return input_idxs
        elif self.auto_search_config.search_algo == &quot;random&quot;:
            return random.sample(input_idxs, len(input_idxs))
        else:
            self.logger.warning(
                f&quot;{self.auto_search_config.search_algo} is not supported yet! return grid_search method!&quot;)
            return input_idxs

    def runner(self, one_config: Dict[str, Any], data_reader: Any) -&gt; None:

        # step 1: set the search config to the self.config
        temp_level1_config, temp_level2_config, temp_level3_config = split_config_levels(one_config)
        if (temp_level1_config != {}) and (temp_level2_config != {}) and \
                (temp_level3_config == {}):
            level1_keys = list(temp_level1_config.keys())
            level2_keys = list(temp_level2_config.keys())
            # set level2 config
            for temp_level2_key in level2_keys:
                self.config.global_quant_config.extra_options[temp_level2_key] = temp_level2_config[temp_level2_key]
            # set level1 config
            for temp_level1_key in level1_keys:
                self.config.global_quant_config.__setattr__(temp_level1_key, temp_level1_config[temp_level1_key])
        elif (temp_level1_config != {}) and (temp_level2_config == {}) and \
                (temp_level3_config != {}):
            level1_keys = list(temp_level1_config.keys())
            # set level1 config
            for temp_level1_key in level1_keys:
                self.config.global_quant_config.__setattr__(temp_level1_key, temp_level1_config[temp_level1_key])
            # set level3 config
            self.config.global_quant_config.extra_options = {&quot;FastFinetune&quot;: temp_level3_config}

        elif (temp_level1_config != {}) and (temp_level2_config != {}) and \
                (temp_level3_config != {}):
            level1_keys = list(temp_level1_config.keys())
            level2_keys = list(temp_level2_config.keys())
            # set level2 config
            for temp_level2_key in level2_keys:
                self.config.global_quant_config.extra_options[temp_level2_key] = temp_level2_config[temp_level2_key]
            # set level1 config
            all_config_atrrs = dir(self.config.global_quant_config)
            for temp_level1_key in level1_keys:
                if temp_level1_key in all_config_atrrs:
                    self.config.global_quant_config.__setattr__(temp_level1_key, temp_level1_config[temp_level1_key])
            # set level3 config
            self.config.global_quant_config.extra_options[&quot;FastFinetune&quot;] = temp_level3_config
        elif (temp_level1_config != {}) and (temp_level2_config == {}) and \
                (temp_level3_config == {}):
            all_config_atrrs = dir(self.config.global_quant_config)
            level1_keys = list(temp_level1_config.keys())
            for temp_level1_key in level1_keys:
                if temp_level1_key in all_config_atrrs:
                    self.config.global_quant_config.__setattr__(temp_level1_key, temp_level1_config[temp_level1_key])

        else:
            self.logger.error(&quot;Your search space if invalid!&quot;)

        # step2: change the config and run
        quantize_start_time = time.time()
        self.quantizer.config = self.config.global_quant_config
        temp_output_path = os.path.join(self.cache_dir, f&quot;iter_{self.iterations}.onnx&quot;)
        self.quantizer.quantize_model(self.model_input, temp_output_path, data_reader)
        quantize_end_time = time.time()

        quantize_time_consumed = quantize_end_time - quantize_start_time
        self.time_consumed += quantize_time_consumed

        # step 3: evalute the quantized model and decide if remove it and log it
        if self.auto_search_config.search_evaluator is None:
            prefix = &quot;model_output&quot;
            quantized_model_res_path = os.path.join(self.cache_dir, &quot;quantized_&quot; + prefix)
            if not os.path.exists(quantized_model_res_path):
                os.makedirs(quantized_model_res_path)
            self.quantized_model_output = self.evaluator(temp_output_path,
                                                         self.eval_dataloader,
                                                         save_path=quantized_model_res_path,
                                                         save_prefix=prefix)
        else:
            self.quantized_model_output = self.evaluator(temp_output_path)

        self.logger.info(f&quot;config_index:{self.iterations}&quot;)
        self.logger.info(f&quot;config: {one_config}&quot;)
        self.logger.info(f&quot;quantized time consumed:{quantize_time_consumed}s&quot;)

        # step 4: calculate the metric difference
        if self.auto_search_config.search_evaluator is None:
            diffs = []
            fp_output_files = os.listdir(self.base_model_output)
            for file in fp_output_files:
                fp_file = os.path.join(self.base_model_output, file)
                quantized_file = os.path.join(self.quantized_model_output, file)
                fp_output = np.load(fp_file)
                quantized_output = np.load(quantized_file)
                diff_item = self.metric(fp_output, quantized_output)
                diffs.append(diff_item)
            # remove the temporay quantized output
            shutil.rmtree(self.quantized_model_output)
            diff = np.mean(diffs)
            metric_name = self.auto_search_config.search_metric if self.auto_search_config.search_metric is not None else &quot;L2&quot;
        else:
            diff = self.base_model_output - self.quantized_model_output
            metric_name = &quot;customer definded&quot;

        self.logger.info(
            f&quot;{metric_name} distance is:{diff}, with tolerance:{self.auto_search_config.search_metric_tolerance}&quot;)
        self.searched_space[self.iterations] = diff

        # step 5: judge the tolerance
        if diff &lt;= self.auto_search_config.search_metric_tolerance:
            save_output_path = os.path.join(self.output_dir, f&quot;iter_{self.iterations}.onnx&quot;)
            shutil.move(temp_output_path, save_output_path)
            temp_one_candidate = {
                &quot;config_index&quot;: self.iterations,
                &quot;difference&quot;: diff,
                &quot;model_path&quot;: save_output_path,
                &quot;config&quot;: one_config
            }
            self.candidates.append(temp_one_candidate)
        else:
            os.remove(temp_output_path)

        # step 6: rebase the config
        self.config = self.config_backup

    def search_model(self, ) -&gt; list[Dict[str, Any]]:
        # step 1: get all configs
        all_configs = self.all_configs

        #  step 2: get the baseline metric
        if self.auto_search_config.search_evaluator is None:
            prefix = &quot;model_output&quot;
            fp_model_res_path = os.path.join(self.cache_dir, &quot;fp_&quot; + prefix)
            if not os.path.exists(fp_model_res_path):
                os.makedirs(fp_model_res_path)
            self.base_model_output = self.evaluator(self.model_input,
                                                    self.eval_dataloader,
                                                    save_path=fp_model_res_path,
                                                    save_prefix=prefix)
        else:
            self.base_model_output = self.evaluator(self.model_input)

        # step 3: use sampler to sample the configs
        all_configs = self.sampler(all_configs)

        stop_flag = False

        # stop condiation settings
        if &quot;find_n_candidates&quot; in self.auto_search_config.search_stop_condition.keys():
            find_n_candidates = self.auto_search_config.search_stop_condition[&quot;find_n_candidates&quot;]
        else:
            find_n_candidates = -1
        if &quot;iteration_limit&quot; in self.auto_search_config.search_stop_condition.keys():
            iteration_limit = self.auto_search_config.search_stop_condition[&quot;iteration_limit&quot;]
        else:
            iteration_limit = -1
        if &quot;time_limit&quot; in self.auto_search_config.search_stop_condition.keys():
            time_limit = self.auto_search_config.search_stop_condition[&quot;time_limit&quot;]

        while not stop_flag:
            # set the initial data reader and run the config
            data_reader_temp = copy.deepcopy(self.calibration_data_reader)
            self.runner(all_configs[self.iterations], data_reader=data_reader_temp)
            self.iterations += 1

            # stop condition list
            if self.iterations == len(all_configs):
                stop_flag = True
            if find_n_candidates != -1 and len(self.candidates) &gt;= find_n_candidates:
                stop_flag = True
            if iteration_limit != -1 and self.iterations &gt;= iteration_limit:
                stop_flag = True
            if time_limit != -1 and self.time_consumed &gt;= time_limit:
                stop_flag = True

        if self.auto_search_config.search_evaluator is None:
            shutil.rmtree(fp_model_res_path)

        self.logger.info(&quot;----------------------------------------------------------------&quot;)
        self.logger.info(&quot;--------------------Sorted searhed space------------------------&quot;)
        self.logger.info(&quot;----------------------------------------------------------------&quot;)
        sorted_diffs = sorted(self.searched_space.items(), key=lambda kv: (kv[1], kv[0]))
        if self.auto_search_config.search_evaluator is None:
            metric_name = self.auto_search_config.search_metric if self.auto_search_config.search_metric is not None else &quot;L2&quot;
        else:
            metric_name = &quot;customer definded&quot;
        for item in sorted_diffs:
            self.logger.info(f&quot;config idex:{item[0]}, {metric_name} distance:{item[1]}&quot;)
        self.logger.info(&quot;----------------------------------------------------------------&quot;)
        self.logger.info(&quot;----------All candidates meeting the target---------------------&quot;)
        self.logger.info(&quot;----------------------------------------------------------------&quot;)
        sorted_iter_nums = [sorted_diffs[i][0] for i in range(len(sorted_diffs))]
        candidates_nums = {}
        for j in range(len(self.candidates)):
            temp_key = self.candidates[j][&quot;config_index&quot;]
            candidates_nums[temp_key] = j
        if len(candidates_nums) == 0:
            self.logger.info(
                &quot;There is no config that meet the tolerance! You can choose a good one from the searched space or you can reset the search space to search aggin!&quot;
            )
        else:
            for i in range(len(sorted_iter_nums)):
                if sorted_iter_nums[i] in list(candidates_nums.keys()):
                    self.logger.info(f&quot;{self.candidates[candidates_nums[sorted_iter_nums[i]]]}&quot;)
        return self.candidates
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer d-print-none">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
            
          </div>
          <footer class="bd-footer-content">
            <p>
      Last updated on Feb 12, 2025.<br/>
  </p>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script defer src="../../../_static/scripts/bootstrap.js?digest=8878045cc6db502f8baf"></script>
<script defer src="../../../_static/scripts/pydata-sphinx-theme.js?digest=8878045cc6db502f8baf"></script>

<footer class="rocm-footer">
    <div class="container-lg">
        <section class="bottom-menu menu py-45">
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <ul>
                        <li><a href="https://www.amd.com/en/corporate/copyright" target="_blank">Terms and Conditions</a></li>
                        <li><a href="https://quark.docs.amd.com/latest/license.html">Quark Licenses and Disclaimers</a></li>
                        <li><a href="https://www.amd.com/en/corporate/privacy" target="_blank">Privacy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/trademarks" target="_blank">Trademarks</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/statement-human-trafficking-forced-labor.pdf" target="_blank">Statement on Forced Labor</a></li>
                        <li><a href="https://www.amd.com/en/corporate/competition" target="_blank">Fair and Open Competition</a></li>
                        <li><a href="https://www.amd.com/system/files/documents/amd-uk-tax-strategy.pdf" target="_blank">UK Tax Strategy</a></li>
                        <li><a href="https://www.amd.com/en/corporate/cookies" target="_blank">Cookie Policy</a></li>
                        <!-- OneTrust Cookies Settings button start -->
                        <li><a href="#cookie-settings" id="ot-sdk-btn" class="ot-sdk-show-settings">Cookie Settings</a></li>
                        <!-- OneTrust Cookies Settings button end -->
                    </ul>
                </div>
            </div>
            <div class="row d-flex align-items-center">
                <div class="col-12 text-center">
                    <div>
                        <span class="copyright">© 2024 Advanced Micro Devices, Inc</span>
                    </div>
                </div>
            </div>
        </section>
    </div>
</footer>

<!-- <div id="rdc-watermark-container">
    <img id="rdc-watermark" src="../../../_static/images/alpha-watermark.svg" alt="DRAFT watermark"/>
</div> -->
  </body>
</html>