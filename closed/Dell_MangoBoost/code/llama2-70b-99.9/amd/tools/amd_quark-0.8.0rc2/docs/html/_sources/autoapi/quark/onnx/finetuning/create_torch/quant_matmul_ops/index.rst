:orphan:

:py:mod:`quark.onnx.finetuning.create_torch.quant_matmul_ops`
=============================================================

.. py:module:: quark.onnx.finetuning.create_torch.quant_matmul_ops


Module Contents
---------------

Classes
~~~~~~~

.. autoapisummary::

   quark.onnx.finetuning.create_torch.quant_matmul_ops.QMatMul




.. py:class:: QMatMul(**kwargs: Any)




   A wrapper for torch layer's input/weight/bias quantization 


