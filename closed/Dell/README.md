# MLPerf Inference v5.1 Implementations
This is a repository of Dell Technologies servers using optimized implementations for [MLPerf Inference Benchmark ](https://github.com/mlcommons/inference).

# Implementations
## Benchmarks
**Please refer to /closed/NVIDIA for detailed instructions for NVIDIA GPU & Triton submissions, including performace guides, and instructions on how to run with new systems.** 

**Please refer to /closed/AMD for detailed instructions for AMD GPU submissions.**

**Please refer to /closed/Intel for detailed instructions for Intel CPU submissions.**
  

